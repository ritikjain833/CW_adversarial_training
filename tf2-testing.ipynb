{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install audiomentations tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:38:21.107006Z","iopub.execute_input":"2023-06-08T06:38:21.107474Z","iopub.status.idle":"2023-06-08T06:38:36.684671Z","shell.execute_reply.started":"2023-06-08T06:38:21.107438Z","shell.execute_reply":"2023-06-08T06:38:36.683618Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting audiomentations\n  Downloading audiomentations-0.30.0-py3-none-any.whl (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.64.1)\nRequirement already satisfied: numpy>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from audiomentations) (1.23.5)\nCollecting librosa<0.10.0,>0.7.2 (from audiomentations)\n  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from audiomentations) (1.10.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (3.0.0)\nRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.2.0)\nRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (5.1.1)\nCollecting resampy>=0.2.2 (from librosa<0.10.0,>0.7.2->audiomentations)\n  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.57.0)\nRequirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (21.3)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.45.1->librosa<0.10.0,>0.7.2->audiomentations) (0.40.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.9)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.28.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa<0.10.0,>0.7.2->audiomentations) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2023.5.7)\nInstalling collected packages: resampy, librosa, audiomentations\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.10.0.post2\n    Uninstalling librosa-0.10.0.post2:\n      Successfully uninstalled librosa-0.10.0.post2\nSuccessfully installed audiomentations-0.30.0 librosa-0.9.2 resampy-0.4.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom argparse import ArgumentParser\nfrom itertools import chain\nimport os\nimport tensorflow as tf\nimport librosa\nfrom audiomentations import Compose, AddBackgroundNoise, TimeMask, Resample\nfrom tqdm import tqdm\nimport tensorflow_addons as tfa\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-08T06:38:41.068036Z","iopub.execute_input":"2023-06-08T06:38:41.068508Z","iopub.status.idle":"2023-06-08T06:38:54.044643Z","shell.execute_reply.started":"2023-06-08T06:38:41.068456Z","shell.execute_reply":"2023-06-08T06:38:54.043432Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"parser=ArgumentParser()\nparser.add_argument(\"--data_dir\",default=\"/kaggle/input/cw-attack-5000/data/\")\nparser.add_argument(\"--batch_size\", default=128, type=int)\nparser.add_argument(\"--lr\", default=0.001, type=float)\nparser.add_argument(\"--weight_decay\", default=1e-4, type=float)\nargs = parser.parse_args([])\nprint(vars(args))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:48:24.600814Z","iopub.execute_input":"2023-06-08T06:48:24.601284Z","iopub.status.idle":"2023-06-08T06:48:24.611873Z","shell.execute_reply.started":"2023-06-08T06:48:24.601251Z","shell.execute_reply":"2023-06-08T06:48:24.610413Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'data_dir': '/kaggle/input/cw-attack-5000/data/', 'batch_size': 128, 'lr': 0.001, 'weight_decay': 0.0001}\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert_to_mfccs(data, perm=None):\n#     print(data.shape)\n    stfts = tf.signal.stft(tf.squeeze(data), frame_length=480, frame_step=160,\n                           fft_length=480)\n    spectrograms = tf.abs(stfts)\n\n    # Warp the linear scale spectrograms into the mel-scale.\n    num_spectrogram_bins = stfts.shape[-1]\n    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 7600.0, 80\n    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n      num_mel_bins, num_spectrogram_bins, 16000, lower_edge_hertz,\n      upper_edge_hertz)\n    mel_spectrograms = tf.tensordot(\n      spectrograms, linear_to_mel_weight_matrix, 1)\n    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n      linear_to_mel_weight_matrix.shape[-1:]))\n\n    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n\n    # Compute MFCCs from log_mel_spectrograms and take the first 13.\n    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n      log_mel_spectrograms)[..., :40]\n    \n    if perm is not None:\n        mfccs = tf.transpose(mfccs).numpy()\n        mfccs = tf.convert_to_tensor(mfccs[perm])\n        mfccs = tf.transpose(mfccs, perm=[2, 0, 1])\n    else:\n        mfccs = tf.transpose(mfccs, perm=[0, 2, 1])\n    mfccs = tf.expand_dims(mfccs, axis=-1)\n    return mfccs","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:08.838139Z","iopub.execute_input":"2023-06-08T06:39:08.838601Z","iopub.status.idle":"2023-06-08T06:39:08.852664Z","shell.execute_reply.started":"2023-06-08T06:39:08.838505Z","shell.execute_reply":"2023-06-08T06:39:08.851163Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_label(file_path):\n    \"\"\"\n    Returns label of an audio file\n    :param file_path:\n    :return: Label\n    \"\"\"\n    parts = tf.strings.split(file_path, os.path.sep)\n    return parts[-2]","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:11.611949Z","iopub.execute_input":"2023-06-08T06:39:11.612350Z","iopub.status.idle":"2023-06-08T06:39:11.619583Z","shell.execute_reply.started":"2023-06-08T06:39:11.612319Z","shell.execute_reply":"2023-06-08T06:39:11.618162Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_mfccs(file_path):\n    \"\"\"\n    Takes an audio file and returns mfcc of the audio file. This will be used to generate\n    the mfcc of validation audio files and test audio files\n    :param file_path: audio file in wav format\n    :return: mfcc\n    \"\"\"\n    signal, sr = librosa.load(file_path, sr=16000)\n    edited_signal = librosa.util.fix_length(signal, 16000)\n#     log_spect = np.log(get_spectrogram(edited_signal) + 1e-6)\n\n#     mfccs = librosa.feature.mfcc(y=edited_signal, n_mfcc=40, sr=sr, S=log_spect)\n    return edited_signal","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:14.263002Z","iopub.execute_input":"2023-06-08T06:39:14.263382Z","iopub.status.idle":"2023-06-08T06:39:14.270491Z","shell.execute_reply.started":"2023-06-08T06:39:14.263353Z","shell.execute_reply":"2023-06-08T06:39:14.269314Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_example(fp,commands,data_dir,trainable=False):\n    file_path=fp\n    mfccs=get_mfccs(file_path)\n    label = get_label(file_path)\n    label = label.numpy().decode('utf-8')\n    label_id = [i for i in range(len(commands)) if commands[i] == label][0]\n#     if mfccs.shape != (40, 98):\n#         print(mfccs.shape)\n        # print(\"not padded\")\n    return np.expand_dims(mfccs, axis=-1), label_id\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:17.100990Z","iopub.execute_input":"2023-06-08T06:39:17.101381Z","iopub.status.idle":"2023-06-08T06:39:17.109520Z","shell.execute_reply.started":"2023-06-08T06:39:17.101351Z","shell.execute_reply":"2023-06-08T06:39:17.108291Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def load_files(data_dir='data'):\n    \"\"\"\n    Loads the speech command data directory and returns the files and the labels\n    :param data_dir:  path to directory containing audio files\n    :return: filenames, commands\n    \"\"\"\n    print(data_dir, '\\n\\n\\n\\n')\n    commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n#     not_needed = ['README.md', 'speech_commands_v0.01.tar.gz', 'validation_list.txt', 'testing_list.txt', 'LICENSE',\n#                   '.DS_Store', '_background_noise_']\n    #commands = ['on', 'off', 'yes', 'no', 'stop', 'go', 'left', 'right', 'up', 'down']\n    commands = ['on', 'off']\n    filenames = []\n    for i in range(len(commands)):\n        filenames.append(tf.io.gfile.glob(str(data_dir) + \"/\" + commands[i] + \"/*.wav\"))\n    filenames = list(chain.from_iterable(filenames))\n    filenames = tf.random.shuffle(filenames)\n    num_samples = len(filenames)\n    print('Number of total examples:', num_samples)\n    return filenames, commands","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:20.652112Z","iopub.execute_input":"2023-06-08T06:39:20.652516Z","iopub.status.idle":"2023-06-08T06:39:20.662906Z","shell.execute_reply.started":"2023-06-08T06:39:20.652485Z","shell.execute_reply":"2023-06-08T06:39:20.661372Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_test_files(filenames,data_dir):\n    with open(os.path.join(data_dir, 'testing_list.txt'), 'r') as f:\n        list_of_test_data = f.read().splitlines()\n    test_files=[]\n    for i in filenames:\n        current_file = i.numpy().decode('utf-8')\n        main_dir, label, data = current_file.rsplit('/', 2)\n        input_data = '/'.join((label, data))\n        if input_data in list_of_test_data:\n            input_data = \"/\".join((data_dir, input_data))\n            test_files.append(input_data)\n    print(\"Completed loading test files\")\n    return test_files\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:23.571000Z","iopub.execute_input":"2023-06-08T06:39:23.571384Z","iopub.status.idle":"2023-06-08T06:39:23.579860Z","shell.execute_reply.started":"2023-06-08T06:39:23.571355Z","shell.execute_reply":"2023-06-08T06:39:23.578615Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_data(test_files,commands,data_dir):\n    test_data=[]\n    test_label=[]\n    for fp in tqdm(test_files):\n\n        data, label =  create_example(fp, commands, data_dir,trainable=False)\n        test_data.append(data)\n        test_label.append(label)\n\n    test_data = np.array(test_data, dtype=np.float32)\n    test_label = np.array(test_label, dtype=np.float32)\n\n    print(f\"Test data shape: {test_data.shape}, test label shape: {test_label.shape}\")\n    return test_data,test_label\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:26.803062Z","iopub.execute_input":"2023-06-08T06:39:26.803462Z","iopub.status.idle":"2023-06-08T06:39:26.811199Z","shell.execute_reply.started":"2023-06-08T06:39:26.803433Z","shell.execute_reply":"2023-06-08T06:39:26.810185Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def collect_data(batch_size,data_dir):\n    filenames,commands=load_files(data_dir)\n    test_files=load_test_files(filenames,data_dir)\n    test_data,test_label=load_data(test_files,commands,data_dir)\n    test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n    return test_ds,commands\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:39:29.300386Z","iopub.execute_input":"2023-06-08T06:39:29.300820Z","iopub.status.idle":"2023-06-08T06:39:29.307138Z","shell.execute_reply.started":"2023-06-08T06:39:29.300786Z","shell.execute_reply":"2023-06-08T06:39:29.305791Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time\nstart=time.time()\nmodel = tf.keras.models.load_model('/kaggle/input/cw-model-5000/KWS_transformer',compile=False)\nmodel.load_weights('/kaggle/input/cw-model-5000/best_weights')\nnp.random.seed(1234)\nperm = np.random.permutation(40)\nmodel.compile(\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(\n            from_logits=True\n        ),\n        optimizer=tfa.optimizers.AdamW(\n            learning_rate=args.lr, weight_decay=args.weight_decay\n        ),\n        metrics=[\"accuracy\"],\n    )\ntest_ds,commands=collect_data(batch_size=args.batch_size,data_dir=args.data_dir)\ntest_ds=test_ds.batch(args.batch_size)\nloss,acc,batches=0,0,0\nfor data,labels in test_ds:\n    mfccs=convert_to_mfccs(data,perm=perm)\n    l,a=model.test_on_batch(mfccs,labels)\n    loss+=l\n    acc+=a\n    batches+=1\nprint(f\"Test: loss:{loss/batches},acc:{acc/batches*100}\")    \nend=time.time()\nprint(end-start)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T06:48:29.661901Z","iopub.execute_input":"2023-06-08T06:48:29.662314Z","iopub.status.idle":"2023-06-08T06:48:59.129287Z","shell.execute_reply.started":"2023-06-08T06:48:29.662283Z","shell.execute_reply":"2023-06-08T06:48:59.128225Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/cw-attack-5000/data/ \n\n\n\n\nNumber of total examples: 7718\nCompleted loading test files\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/128 [00:00<?, ?it/s]/tmp/ipykernel_32/387395141.py:9: FutureWarning: Pass size=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n  edited_signal = librosa.util.fix_length(signal, 16000)\n100%|██████████| 128/128 [00:00<00:00, 131.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test data shape: (128, 16000, 1), test label shape: (128,)\nTest: loss:3.6155033111572266,acc:34.375\n29.454954147338867\n","output_type":"stream"}]}]}