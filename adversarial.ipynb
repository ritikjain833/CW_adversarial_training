{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b453feb3",
   "metadata": {},
   "source": [
    "# Keyword Transformer model used for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd15fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 16:57:36.956174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Neccessary modules to import\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import os\n",
    "import librosa\n",
    "from audiomentations import Compose, AddBackgroundNoise, SpecFrequencyMask, TimeMask, Resample\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "from shutil import copyfile\n",
    "import scipy.io.wavfile as wav\n",
    "import struct\n",
    "import time\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323bc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Class for Multi Head Self Attention layer\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "#         self.initializer = tf.\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Prenorm transformer block of  KWS streaming layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "        # print(f'out 1 shape: {out1.shape}')\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        # print(f'mlp output shape: {mlp_output.shape}')\n",
    "\n",
    "        return mlp_output + out1\n",
    "\n",
    "\n",
    "class KWS_transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Model architecture of main Key Word Spotting model\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, patch_size, num_layers, num_classes, d_model, num_heads, mlp_dim, channels=1,\n",
    "                 dropout=0.1, ):\n",
    "        super(KWS_transformer, self).__init__()\n",
    "        self.image_width = image_size[0]\n",
    "        self.image_height = image_size[1]\n",
    "        self.patch_width = patch_size[0]\n",
    "        self.patch_height = patch_size[1]\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        num_patches = int((self.image_width * self.image_height) / (self.patch_width * self.patch_height))\n",
    "        patch_dim = channels * self.patch_width * self.patch_height\n",
    "        self.patch_dim = patch_dim\n",
    "\n",
    "        self.pos_emb = self.add_weight(\"pos_emb\", shape=(1, num_patches + 1, d_model))\n",
    "        self.patch_proj = Dense(d_model)\n",
    "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "\n",
    "        self.enc_layers = [\n",
    "            TransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.mlp_head = tf.keras.Sequential(\n",
    "            [\n",
    "                LayerNormalization(epsilon=1e-6),\n",
    "                Dense(num_classes)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def extract_patches(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_width, self.patch_height, 1],\n",
    "            strides=[1, self.patch_width, self.patch_height, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\n",
    "        return patches\n",
    "\n",
    "    def call(self, x, training):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        patches = self.extract_patches(x)\n",
    "\n",
    "        x = self.patch_proj(patches)\n",
    "\n",
    "        class_emb = tf.broadcast_to(self.class_emb, [batch_size, 1, self.d_model])\n",
    "        x = tf.concat([class_emb, x], axis=1)\n",
    "        x = x + self.pos_emb\n",
    "\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training)\n",
    "\n",
    "        x = self.mlp_head(x[:, 0])\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4f8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': 'data4/', 'logdir': 'logs', 'num_layers': 12, 'd_model': 64, 'num_heads': 1, 'mlp_dim': 256, 'lr': 0.001, 'weight_decay': 0.0001, 'batch_size': 128, 'epochs': 200, 'save_dir': 'adv_KWS_transformer2'}\n",
      "/bin/bash: /home/ritik/miniconda3/envs/project/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "mkdir: cannot create directory ‘adv_tmp’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--data_dir\", default=\"data4/\")\n",
    "parser.add_argument(\"--logdir\", default=\"logs\")\n",
    "parser.add_argument(\"--num_layers\", default=12, type=int)\n",
    "parser.add_argument(\"--d_model\", default=64, type=int)\n",
    "parser.add_argument(\"--num_heads\", default=1, type=int)\n",
    "parser.add_argument(\"--mlp_dim\", default=256, type=int)\n",
    "parser.add_argument(\"--lr\", default=0.001, type=float)\n",
    "parser.add_argument(\"--weight_decay\", default=1e-4, type=float)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--epochs\", default=200, type=int)\n",
    "parser.add_argument(\"--save_dir\", default=\"adv_KWS_transformer2\")\n",
    "args = parser.parse_args([])\n",
    "print(vars(args))\n",
    "!mkdir adv_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ec5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mfccs(data, perm=None):\n",
    "#     print(data.shape)\n",
    "    stfts = tf.signal.stft(tf.squeeze(data), frame_length=480, frame_step=160,\n",
    "                           fft_length=480)\n",
    "    spectrograms = tf.abs(stfts)\n",
    "\n",
    "    # Warp the linear scale spectrograms into the mel-scale.\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 7600.0, 80\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, 16000, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(\n",
    "      spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
    "      linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "    # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n",
    "      log_mel_spectrograms)[..., :40]\n",
    "    \n",
    "    if perm is not None:\n",
    "        mfccs = tf.transpose(mfccs).numpy()\n",
    "        mfccs = tf.convert_to_tensor(mfccs[perm])\n",
    "        mfccs = tf.transpose(mfccs, perm=[2, 0, 1])\n",
    "    else:\n",
    "        mfccs = tf.transpose(mfccs, perm=[0, 2, 1])\n",
    "    mfccs = tf.expand_dims(mfccs, axis=-1)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3768cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(data_dir='data'):\n",
    "    \"\"\"\n",
    "    Loads the speech command data directory and returns the files and the labels\n",
    "    :param data_dir:  path to directory containing audio files\n",
    "    :return: filenames, commands\n",
    "    \"\"\"\n",
    "    print(data_dir, '\\n\\n\\n\\n')\n",
    "    commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "#     not_needed = ['README.md', 'speech_commands_v0.01.tar.gz', 'validation_list.txt', 'testing_list.txt', 'LICENSE',\n",
    "#                   '.DS_Store', '_background_noise_']\n",
    "    #commands = ['on', 'off', 'yes', 'no', 'stop', 'go', 'left', 'right', 'up', 'down']\n",
    "    commands = ['on', 'off']\n",
    "    filenames = []\n",
    "    for i in range(len(commands)):\n",
    "        filenames.append(tf.io.gfile.glob(str(data_dir) + \"/\" + commands[i] + \"/*.wav\"))\n",
    "    filenames = list(chain.from_iterable(filenames))\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    num_samples = len(filenames)\n",
    "    print('Number of total examples:', num_samples)\n",
    "    # print('Number of examples per label:',\n",
    "    #       len(tf.io.gfile.listdir(os.path.join(data_dir, commands[0]))))\n",
    "    # print('Example file tensor:', filenames[0])\n",
    "#     print(filenames)\n",
    "#     with open(\"filenames.txt\", 'w') as f:\n",
    "#         for x in filenames:\n",
    "#             f.write(x + '\\n')\n",
    "    return filenames, commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07fa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_val_files(filenames, data_dir):\n",
    "    \"\"\"\n",
    "    Takes a list of files as input and returns list of train files, val files and test files\n",
    "    :param filenames: List of audio files\n",
    "    :param data_dir: Path to audio files\n",
    "    :return: train files, test files and val files\n",
    "    \"\"\"\n",
    "    with open(os.path.join(data_dir, 'validation_list.txt'), 'r') as f:\n",
    "        list_of_val_data = f.read().splitlines()\n",
    "\n",
    "    with open(os.path.join(data_dir, 'testing_list.txt'), 'r') as f:\n",
    "        list_of_test_data = f.read().splitlines()\n",
    "\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    test_files = []\n",
    "    for i in filenames:\n",
    "        current_file = i.numpy().decode('utf-8')\n",
    "        main_dir, label, data = current_file.rsplit('/', 2)\n",
    "        input_data = '/'.join((label, data))\n",
    "\n",
    "        if input_data in list_of_val_data:\n",
    "            input_data = \"/\".join((data_dir, input_data))\n",
    "            val_files.append(input_data)\n",
    "        elif input_data in list_of_test_data:\n",
    "            input_data = \"/\".join((data_dir, input_data))\n",
    "            test_files.append(input_data)\n",
    "        else:\n",
    "            input_data = \"/\".join((data_dir, input_data))\n",
    "            train_files.append(input_data)\n",
    "    print(\"Completed loading train files, test files and validation files\")\n",
    "    return train_files, test_files, val_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe0c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    \"\"\"\n",
    "    Returns label of an audio file\n",
    "    :param file_path:\n",
    "    :return: Label\n",
    "    \"\"\"\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d18a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfccs(file_path):\n",
    "    \"\"\"\n",
    "    Takes an audio file and returns mfcc of the audio file. This will be used to generate\n",
    "    the mfcc of validation audio files and test audio files\n",
    "    :param file_path: audio file in wav format\n",
    "    :return: mfcc\n",
    "    \"\"\"\n",
    "    #loads the audio wavefile as numpy array \n",
    "    signal, sr = librosa.load(file_path, sr=16000)\n",
    "    #edit the signal to length of duration of signal to 16000\n",
    "    edited_signal = librosa.util.fix_length(signal, 16000)\n",
    "#     log_spect = np.log(get_spectrogram(edited_signal) + 1e-6)\n",
    "\n",
    "#     mfccs = librosa.feature.mfcc(y=edited_signal, n_mfcc=40, sr=sr, S=log_spect)\n",
    "    return edited_signal\n",
    "\n",
    "\n",
    "def get_mfccs_augmented(file_path, data_dir):\n",
    "    \"\"\"\n",
    "    Takes an audio file and returns augmented mfcc of the audio file. This will be used to\n",
    "    generate the mfcc of training set audio files\n",
    "    :param file_path: audio file in wav format\n",
    "    :param data_dir:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    signal, sr = librosa.load(file_path, sr=16000)\n",
    "    edited_signal = librosa.util.fix_length(signal, 16000)\n",
    "    start_ = int(np.random.uniform(-1600, 1600))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[edited_signal[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), edited_signal[:start_]]\n",
    "\n",
    "    augment = Compose([\n",
    "        Resample(min_sample_rate=16000 * 0.85, max_sample_rate=16000 * 1.15),\n",
    "        TimeMask(min_band_part=0.0, max_band_part=0.255),\n",
    "        AddBackgroundNoise(sounds_path=os.path.join(data_dir, '_background_noise_'))\n",
    "    ])\n",
    "    edited_signal = augment(samples=wav_time_shift, sample_rate=16000)\n",
    "    edited_signal = librosa.util.fix_length(edited_signal, 16000)\n",
    "#     spect = get_spectrogram(edited_signal)\n",
    "#     spect = SpecFrequencyMask(min_mask_fraction=0, max_mask_fraction=0.175)(spect)\n",
    "\n",
    "#     log_spec = np.log(spect + 1e-6)\n",
    "\n",
    "#     mfccs = librosa.feature.mfcc(y=edited_signal, n_mfcc=40, sr=sr, S=log_spec)\n",
    "    return edited_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816d0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(fp, commands, data_dir, trainable=True):\n",
    "    \"\"\"\n",
    "\n",
    "    :param fp: file path\n",
    "    :param commands: list of labels\n",
    "    :param data_dir: directory of audio files\n",
    "    :param trainable: bool parameter for creating train set or test set and val set\n",
    "    :return:mfcc, label\n",
    "    \"\"\"\n",
    "    file_path = fp\n",
    "    if trainable:\n",
    "        mfccs = get_mfccs_augmented(file_path, data_dir)\n",
    "    else:\n",
    "        mfccs = get_mfccs(file_path)\n",
    "    label = get_label(file_path)\n",
    "    label = label.numpy().decode('utf-8')\n",
    "    label_id = [i for i in range(len(commands)) if commands[i] == label][0]\n",
    "#     if mfccs.shape != (40, 98):\n",
    "#         print(mfccs.shape)\n",
    "        # print(\"not padded\")\n",
    "    return np.expand_dims(mfccs, axis=-1), label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ec334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_files, test_files, val_files, commands, data_dir):\n",
    "    \"\"\"\n",
    "    creates training, testing and validation data and labels\n",
    "    :param train_files:\n",
    "    :param test_files:\n",
    "    :param val_files:\n",
    "    :param commands:\n",
    "    :param data_dir:\n",
    "    :return: train_data, train_label, test_data, test_label, val_data, val_label\n",
    "    \"\"\"\n",
    "\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    val_data = []\n",
    "    val_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "\n",
    "    for fp in tqdm(train_files):\n",
    "\n",
    "        data, label = create_example(fp, commands, data_dir,trainable=True)\n",
    "        train_data.append(data)\n",
    "        train_label.append(label)\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.float32)\n",
    "    train_label = np.array(train_label, dtype=np.float32)\n",
    "    print(f\"Train data shape: {train_data.shape}, train label shape: {train_label.shape}\")\n",
    "\n",
    "    for fp in tqdm(val_files):\n",
    "\n",
    "        data, label = create_example(fp, commands, data_dir,trainable=False)\n",
    "        val_data.append(data)\n",
    "        val_label.append(label)\n",
    "\n",
    "    val_data = np.array(val_data, dtype=np.float32)\n",
    "    val_label = np.array(val_label, dtype=np.float32)\n",
    "    print(f\"Validation data shape: {val_data.shape}, validation label shape: {val_label.shape}\")\n",
    "\n",
    "    for fp in tqdm(test_files):\n",
    "\n",
    "        data, label =  create_example(fp, commands, data_dir,trainable=False)\n",
    "        test_data.append(data)\n",
    "        test_label.append(label)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.float32)\n",
    "    test_label = np.array(test_label, dtype=np.float32)\n",
    "\n",
    "    print(f\"Test data shape: {test_data.shape}, test label shape: {test_label.shape}\")\n",
    "    return train_data, train_label, test_data, test_label, val_data, val_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df61f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(batch_size, data_dir):\n",
    "    \"\"\"\n",
    "    Takes batch size and data directory as input and returns train_ds, test_ds and val_Ds\n",
    "    :param batch_size: batch size of train set and val set\n",
    "    :param data_dir:\n",
    "    :return: train_ds, test_ds, val_ds, commands\n",
    "    \"\"\"\n",
    "    filenames, commands = load_files(data_dir)\n",
    "    train_files, test_files, val_files = load_train_test_val_files(filenames, data_dir)\n",
    "    train_data, train_label, test_data, test_label, val_data, val_label = load_data(train_files, test_files, val_files, commands, data_dir)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    val_ds = val_ds.batch(batch_size)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "    return train_ds, test_ds, val_ds, commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cd014",
   "metadata": {},
   "source": [
    "# Attack process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3b0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910f4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_step(model, optimizer, loss_fn, original, delta, rescale, target):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([delta])\n",
    "#         print(delta.shape, rescale.shape)\n",
    "        new_delta = tf.clip_by_value(delta, -2000, 2000)*rescale\n",
    "        new_input = new_delta + original\n",
    "        noise = tf.random.normal(new_input.shape, stddev=2)\n",
    "        new_input = tf.clip_by_value(new_input+noise, -2**15, 2**15-1)\n",
    "#         print('input:', new_input.shape)\n",
    "        stfts = tf.signal.stft(new_input, frame_length=480, frame_step=160, fft_length=480)\n",
    "        spectrograms = tf.abs(stfts)\n",
    "#         print('stft:', stfts.shape)\n",
    "        # Warp the linear scale spectrograms into the mel-scale.\n",
    "        num_spectrogram_bins = stfts.shape[-1]\n",
    "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 7600.0, 80\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "          num_mel_bins, num_spectrogram_bins, 16000, lower_edge_hertz,\n",
    "          upper_edge_hertz)\n",
    "#         print(linear_to_mel_weight_matrix.shape)\n",
    "        mel_spectrograms = tf.tensordot(\n",
    "          spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "#         print(mel_spectrograms.shape)\n",
    "        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
    "          linear_to_mel_weight_matrix.shape[-1:]))\n",
    "#         print(mel_spectrograms.shape)\n",
    "        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "        # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n",
    "          log_mel_spectrograms)[..., :40]\n",
    "        mfccs = tf.transpose(mfccs, perm=[0,2,1])\n",
    "        mfccs = tf.expand_dims(mfccs, axis=-1)\n",
    "\n",
    "        pred = model(mfccs)\n",
    "\n",
    "        loss = loss_fn(target, pred)\n",
    "    dd = tape.gradient(loss, [delta])\n",
    "#             print('\\n\\n\\nhere\\n\\n\\n', grad, var)\n",
    "    optimizer.apply_gradients(zip(dd,[delta]))\n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "def attack(audio, files, target, model, root = 'tmp', optimizer = tf.optimizers.Adam(learning_rate=10), \n",
    "           loss_fn=tf.nn.sparse_softmax_cross_entropy_with_logits):\n",
    "    batch_size = len(audio)\n",
    "    delta = tf.Variable(np.zeros((batch_size, 16000), dtype=np.float32))\n",
    "    rescale = tf.Variable(np.ones((batch_size, 1), dtype = np.float32))\n",
    "    original = tf.convert_to_tensor(np.array(audio, dtype=np.float32))\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    new_input = (original + delta).numpy()\n",
    "    \n",
    "    # Here we'll keep track of the best solution we've found so far\n",
    "    final_deltas = [None]*batch_size\n",
    "\n",
    "\n",
    "\n",
    "    # We'll make a bunch of iterations of gradient descent here\n",
    "    #now = time.time()\n",
    "    #Here, iteration refers to the number of optimization steps to find the adversarial example.\n",
    "    #Each iteration involves solving an optimization problem to refine the added perturbation added to the original sample\n",
    "    \n",
    "    MAX = 100\n",
    "    first_hits = np.zeros((batch_size,))\n",
    "    best_hits = np.zeros((batch_size,))\n",
    "    start = time.time()\n",
    "    for i in range(MAX):\n",
    "\n",
    "        pred, loss = training_step(model, optimizer, loss_fn, original, delta, rescale, target)\n",
    "\n",
    "\n",
    "        # Print out some debug information every 10 iterations.\n",
    "        if i%100 == 0:\n",
    "#             print(pred.shape, pred)\n",
    "            print(time.time() - start)\n",
    "            print(i, loss, np.argmax(pred, axis=1))\n",
    "\n",
    "\n",
    "        # Actually do the optimization step\n",
    "        for ii in range(batch_size):\n",
    "            if (i%100 == 0 and np.argmax(pred[ii]) == target[ii]) \\\n",
    "               or (i == MAX-1 and final_deltas[ii] is None):\n",
    "                temp_rescale = rescale.numpy()\n",
    "                # Get the current constant\n",
    "                if temp_rescale[ii][0]*2000 > np.max(np.abs(delta[ii])):\n",
    "                    print(\"It's way over\", np.max(np.abs(delta[ii]))/2000.0)\n",
    "                    temp_rescale[ii][0] = np.max(np.abs(delta[ii]))/2000.0\n",
    "\n",
    "                temp_rescale[ii][0] *= .9\n",
    "                rescale.assign(temp_rescale)\n",
    "                # Adjust the best solution found so far\n",
    "                new_input[ii] = (original[ii] + delta[ii]).numpy()\n",
    "                final_deltas[ii] = new_input[ii]\n",
    "\n",
    "                print(\"Worked i=%d loss=%f bound=%f\"%(ii, loss[ii], 2000*rescale[ii][0]))\n",
    "\n",
    "                if (first_hits[ii] == 0):\n",
    "                    print(\"First hit for audio {} at iteration {}\".format(ii, i))\n",
    "                    first_hits[ii]=i\n",
    "                else:\n",
    "                    best_hits[ii]=i\n",
    "\n",
    "                # Just for debugging, save the adversarial example\n",
    "                # to /tmp so we can see it if we want\n",
    "                wav.write(f'{root}/{files[ii]}', 16000,\n",
    "                          np.array(np.clip(np.round(new_input[ii]),\n",
    "                                           -2**15, 2**15-1),dtype=np.int16))\n",
    "    runtime = time.time() - start           \n",
    "\n",
    "    return final_deltas, first_hits, best_hits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48b2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_attack(val):\n",
    "    commands=['on','off']\n",
    "    #commands = ['on', 'off', 'yes', 'no', 'stop', 'go', 'left', 'right', 'up', 'down']\n",
    "    data_dir = 'data3/'\n",
    "    filenames = []\n",
    "    for i in range(len(commands)):\n",
    "        filenames.append(tf.io.gfile.glob(str(data_dir) + commands[i] + \"/*.wav\"))\n",
    "    filenames = list(chain.from_iterable(filenames))\n",
    "    #print(filenames)\n",
    "    #os.makedirs(\"tp/{val}\".format(val=0), exist_ok=True)\n",
    "    random.shuffle(filenames)  \n",
    "    for i in range(0, 2):\n",
    "        os.makedirs('adv_tmp/{k}/'.format(k=val) + commands[i], exist_ok=True)\n",
    "        #os.mkdir('adv_tmp/' + commands[i])\n",
    "        curr= \"adv_tmp/{k}\".format(k=val)       \n",
    "        print(curr)\n",
    "        batch_size = 128\n",
    "        audios = []\n",
    "        files = []\n",
    "        j = -1\n",
    "        while len(audios) < batch_size:\n",
    "            j += 1\n",
    "            #print(j,len(audios))\n",
    "            fs, audio = wav.read(filenames[j])\n",
    "            if filenames[j].split('/')[-2] == commands[i]:\n",
    "                continue\n",
    "            if audio.shape[0] == 16000:\n",
    "                audios.append(audio)\n",
    "                files.append('_'.join(filenames[j].split('/')[-2:]))\n",
    "        target = np.array([i]*len(audios))\n",
    "        rt=curr+\"/\"+commands[i]\n",
    "        print(rt)\n",
    "        deltas, firsts, bests = attack(audios, files, target, \n",
    "                                       model, root=rt)\n",
    "        #print(len(audios))\n",
    "    #adv_train=\"adv_tmp/{k}\".format(k=val)   \n",
    "    if val==\"train\":                \n",
    "        adv_train_ds=collect_train_adversarial_data(batch_size,data_dir=\"adv_tmp/{k}\".format(k=val))\n",
    "        print(\"adversarial train data uploaded\")\n",
    "        return adv_train_ds\n",
    "    else:\n",
    "        adv_test_ds=collect_test_adversarial_data(batch_size,data_dir=\"adv_tmp/{k}\".format(k=val))\n",
    "        print(\"adversarial test data uploaded\")\n",
    "        return adv_test_ds          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94badbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_train_adversarial_data(batch_size,data_dir):\n",
    "    filenames,commands=load_files(data_dir)\n",
    "    adv_train_files=[]\n",
    "    for i in filenames:\n",
    "        current_file = i.numpy().decode('utf-8')\n",
    "        main_dir, label, data = current_file.rsplit('/', 2)\n",
    "        input_data = '/'.join((label, data))\n",
    "        input_data = \"/\".join((data_dir, input_data))\n",
    "        adv_train_files.append(input_data)\n",
    "    adv_train_data,adv_train_label=load_train_adversarial_data(adv_train_files,commands, data_dir)   \n",
    "    adv_train_ds = tf.data.Dataset.from_tensor_slices((adv_train_data, adv_train_label))\n",
    "    adv_train_ds = adv_train_ds.batch(batch_size)    \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    adv_train_ds = adv_train_ds.cache().prefetch(AUTOTUNE)\n",
    "    return adv_train_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959af64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_adversarial_data(adv_train_files,commands,data_dir):\n",
    "    adv_train_data = []\n",
    "    adv_train_label = []\n",
    "\n",
    "    for fp in tqdm(adv_train_files):\n",
    "\n",
    "        data, label = create_example(fp, commands, data_dir,trainable=True)\n",
    "        adv_train_data.append(data)\n",
    "        adv_train_label.append(label)\n",
    "\n",
    "    adv_train_data = np.array(adv_train_data, dtype=np.float32)\n",
    "    adv_train_label = np.array(adv_train_label, dtype=np.float32)\n",
    "    print(f\"Adversarial Train data shape: {adv_train_data.shape}, adv train label shape: {adv_train_label.shape}\")\n",
    "    return adv_train_data, adv_train_label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c493efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_test_adversarial_data(batch_size,data_dir):\n",
    "    filenames,commands=load_files(data_dir)\n",
    "    adv_test_files=[]\n",
    "    for i in filenames:\n",
    "        current_file = i.numpy().decode('utf-8')\n",
    "        main_dir, label, data = current_file.rsplit('/', 2)\n",
    "        input_data = '/'.join((label, data))\n",
    "        input_data = \"/\".join((data_dir, input_data))\n",
    "        adv_test_files.append(input_data)\n",
    "    adv_test_data,adv_test_label=load_test_adversarial_data(adv_test_files,commands, data_dir)   \n",
    "    adv_test_ds = tf.data.Dataset.from_tensor_slices((adv_test_data, adv_test_label))\n",
    "    return adv_test_ds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "428feb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_adversarial_data(adv_test_files,commands,data_dir):\n",
    "    adv_test_data=[]\n",
    "    adv_test_label=[]\n",
    "    for fp in tqdm(adv_test_files):\n",
    "\n",
    "        data, label =  create_example(fp, commands, data_dir,trainable=False)\n",
    "        adv_test_data.append(data)\n",
    "        adv_test_label.append(label)\n",
    "\n",
    "    adv_test_data = np.array(adv_test_data, dtype=np.float32)\n",
    "    adv_test_label = np.array(adv_test_label, dtype=np.float32)\n",
    "\n",
    "    print(f\"Adversarial Test data shape: {test_data.shape},adv  test label shape: {test_label.shape}\")\n",
    "    return adv_test_data,adv_test_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a5c9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data4/ \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 16:58:19.318677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 16:58:19.373982: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 256\n",
      "Completed loading train files, test files and validation files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/205 [00:00<?, ?it/s]/tmp/ipykernel_757409/1167455985.py:27: FutureWarning: Pass size=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  edited_signal = librosa.util.fix_length(signal, 16000)\n",
      "/home/ritik/miniconda3/envs/project/lib/python3.10/site-packages/audiomentations/core/transforms_interface.py:57: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_757409/1167455985.py:40: FutureWarning: Pass size=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  edited_signal = librosa.util.fix_length(edited_signal, 16000)\n",
      "  0%|▏                                          | 1/205 [00:01<06:11,  1.82s/it]/tmp/ipykernel_757409/1167455985.py:27: FutureWarning: Pass size=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  edited_signal = librosa.util.fix_length(signal, 16000)\n",
      "/home/ritik/miniconda3/envs/project/lib/python3.10/site-packages/audiomentations/core/transforms_interface.py:57: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 205/205 [00:07<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (205, 16000, 1), train label shape: (205,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/26 [00:00<?, ?it/s]/tmp/ipykernel_757409/1167455985.py:11: FutureWarning: Pass size=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  edited_signal = librosa.util.fix_length(signal, 16000)\n",
      "100%|██████████████████████████████████████████| 26/26 [00:00<00:00, 185.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data shape: (26, 16000, 1), validation label shape: (26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 162.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (25, 16000, 1), test label shape: (25,)\n",
      "train_ds, test_ds, val_ds uploaded\n",
      "Epoch: 0, Train: Loss: 2.0559662580490112, acc: 52.27780044078827\n",
      "Attack started for training\n",
      "adv_tmp/train\n",
      "adv_tmp/train/on\n",
      "6.045578956604004\n",
      "0 tf.Tensor(\n",
      "[2.5809968  1.9118689  1.2249259  1.9941155  2.7862592  2.58244\n",
      " 2.0172446  2.8544574  2.4939418  2.1568367  1.6102756  2.4597785\n",
      " 2.1128263  2.701904   1.8575244  2.9696805  2.675003   1.5776458\n",
      " 2.13171    2.04317    3.2562172  2.7681055  2.1614366  2.1340156\n",
      " 3.540911   2.576128   1.7812554  3.096835   3.134635   1.076016\n",
      " 1.6844064  2.5321128  1.2878203  3.1127498  2.2758074  2.586039\n",
      " 1.5648166  1.3876863  1.9232882  3.0678082  2.4954948  2.2295403\n",
      " 2.6195586  2.3357348  2.6445305  2.7924843  2.8056753  1.612969\n",
      " 2.8838348  0.82814014 2.1755493  2.1866598  3.1508183  2.4662993\n",
      " 2.1469667  1.5666512  2.5676205  3.2386463  1.6329505  2.0729096\n",
      " 2.9727378  1.7016674  2.0211258  1.9746312  2.1402435  2.3724895\n",
      " 2.3922675  2.1079173  2.4417734  1.995168   3.055674   2.823848\n",
      " 3.114478   2.8134122  2.7510653  2.7992883  2.8895004  2.726281\n",
      " 2.169297   1.3348289  2.2589943  1.3467598  2.0823803  2.3592799\n",
      " 2.2382042  1.9731026  2.2490904  1.5848591  1.1924932  2.7963073\n",
      " 1.4120965  1.9574456  3.1545038  1.2785239  1.4007121  1.9089711\n",
      " 2.445412   1.9680231  2.1851175  2.1234176  1.3980781  2.2556453\n",
      " 2.1638687  2.64165    2.65893    3.3831801  2.7711399  2.8363516\n",
      " 1.6973009  2.9952075  1.5428661  1.7836438  1.810612   3.0276647\n",
      " 2.7667513  2.0523727  1.8524786  2.0747638  2.5749226  2.6982646\n",
      " 2.9756293  3.0198407  2.7974756  1.6468229  3.245337   2.2781732\n",
      " 2.4808726  2.1504302 ], shape=(128,), dtype=float32) [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "It's way over 0.09542854309082031\n",
      "Worked i=0 loss=0.001038 bound=171.771378\n",
      "First hit for audio 0 at iteration 99\n",
      "It's way over 0.12217481231689453\n",
      "Worked i=1 loss=0.001115 bound=219.914658\n",
      "First hit for audio 1 at iteration 99\n",
      "It's way over 0.08635928344726562\n",
      "Worked i=2 loss=0.000936 bound=155.446701\n",
      "First hit for audio 2 at iteration 99\n",
      "It's way over 0.1127308349609375\n",
      "Worked i=3 loss=0.001024 bound=202.915512\n",
      "First hit for audio 3 at iteration 99\n",
      "It's way over 0.09303353118896485\n",
      "Worked i=4 loss=0.001001 bound=167.460358\n",
      "First hit for audio 4 at iteration 99\n",
      "It's way over 0.09628313446044921\n",
      "Worked i=5 loss=0.002540 bound=173.309647\n",
      "First hit for audio 5 at iteration 99\n",
      "It's way over 0.1050487060546875\n",
      "Worked i=6 loss=0.001881 bound=189.087677\n",
      "First hit for audio 6 at iteration 99\n",
      "It's way over 0.09017329406738281\n",
      "Worked i=7 loss=0.000828 bound=162.311935\n",
      "First hit for audio 7 at iteration 99\n",
      "It's way over 0.0994830093383789\n",
      "Worked i=8 loss=0.000821 bound=179.069412\n",
      "First hit for audio 8 at iteration 99\n",
      "It's way over 0.08061631774902343\n",
      "Worked i=9 loss=0.001464 bound=145.109375\n",
      "First hit for audio 9 at iteration 99\n",
      "It's way over 0.10018792724609375\n",
      "Worked i=10 loss=0.001468 bound=180.338257\n",
      "First hit for audio 10 at iteration 99\n",
      "It's way over 0.09104636383056641\n",
      "Worked i=11 loss=0.002005 bound=163.883453\n",
      "First hit for audio 11 at iteration 99\n",
      "It's way over 0.10369109344482422\n",
      "Worked i=12 loss=0.000789 bound=186.643967\n",
      "First hit for audio 12 at iteration 99\n",
      "It's way over 0.09680436706542969\n",
      "Worked i=13 loss=0.003241 bound=174.247864\n",
      "First hit for audio 13 at iteration 99\n",
      "It's way over 0.10299603271484375\n",
      "Worked i=14 loss=0.000940 bound=185.392868\n",
      "First hit for audio 14 at iteration 99\n",
      "It's way over 0.08704967498779297\n",
      "Worked i=15 loss=0.000803 bound=156.689423\n",
      "First hit for audio 15 at iteration 99\n",
      "It's way over 0.09807111358642578\n",
      "Worked i=16 loss=0.001179 bound=176.528000\n",
      "First hit for audio 16 at iteration 99\n",
      "It's way over 0.08608149719238281\n",
      "Worked i=17 loss=0.001130 bound=154.946701\n",
      "First hit for audio 17 at iteration 99\n",
      "It's way over 0.10529153442382813\n",
      "Worked i=18 loss=0.002006 bound=189.524765\n",
      "First hit for audio 18 at iteration 99\n",
      "It's way over 0.09415778350830079\n",
      "Worked i=19 loss=0.002138 bound=169.484024\n",
      "First hit for audio 19 at iteration 99\n",
      "It's way over 0.1054588394165039\n",
      "Worked i=20 loss=0.001205 bound=189.825912\n",
      "First hit for audio 20 at iteration 99\n",
      "It's way over 0.08455819702148437\n",
      "Worked i=21 loss=0.001338 bound=152.204758\n",
      "First hit for audio 21 at iteration 99\n",
      "It's way over 0.104190185546875\n",
      "Worked i=22 loss=0.001911 bound=187.542328\n",
      "First hit for audio 22 at iteration 99\n",
      "It's way over 0.1021247787475586\n",
      "Worked i=23 loss=0.000654 bound=183.824600\n",
      "First hit for audio 23 at iteration 99\n",
      "It's way over 0.09466777801513672\n",
      "Worked i=24 loss=0.001701 bound=170.402008\n",
      "First hit for audio 24 at iteration 99\n",
      "It's way over 0.09512770080566406\n",
      "Worked i=25 loss=0.002508 bound=171.229874\n",
      "First hit for audio 25 at iteration 99\n",
      "It's way over 0.10400332641601563\n",
      "Worked i=26 loss=0.000851 bound=187.205978\n",
      "First hit for audio 26 at iteration 99\n",
      "It's way over 0.10284458923339844\n",
      "Worked i=27 loss=0.002101 bound=185.120255\n",
      "First hit for audio 27 at iteration 99\n",
      "It's way over 0.10388560485839844\n",
      "Worked i=28 loss=0.001688 bound=186.994095\n",
      "First hit for audio 28 at iteration 99\n",
      "It's way over 0.09344874572753906\n",
      "Worked i=29 loss=0.001065 bound=168.207733\n",
      "First hit for audio 29 at iteration 99\n",
      "It's way over 0.12910223388671874\n",
      "Worked i=30 loss=0.002801 bound=232.384018\n",
      "First hit for audio 30 at iteration 99\n",
      "It's way over 0.11564522552490235\n",
      "Worked i=31 loss=0.001074 bound=208.161392\n",
      "First hit for audio 31 at iteration 99\n",
      "It's way over 0.09721318054199218\n",
      "Worked i=32 loss=0.001085 bound=174.983719\n",
      "First hit for audio 32 at iteration 99\n",
      "It's way over 0.09456168365478515\n",
      "Worked i=33 loss=0.002082 bound=170.211029\n",
      "First hit for audio 33 at iteration 99\n",
      "It's way over 0.120636962890625\n",
      "Worked i=34 loss=0.001381 bound=217.146530\n",
      "First hit for audio 34 at iteration 99\n",
      "It's way over 0.10160002899169922\n",
      "Worked i=35 loss=0.002244 bound=182.880051\n",
      "First hit for audio 35 at iteration 99\n",
      "It's way over 0.1176175537109375\n",
      "Worked i=36 loss=0.001340 bound=211.711594\n",
      "First hit for audio 36 at iteration 99\n",
      "It's way over 0.1009532241821289\n",
      "Worked i=37 loss=0.000575 bound=181.715805\n",
      "First hit for audio 37 at iteration 99\n",
      "It's way over 0.11338264465332032\n",
      "Worked i=38 loss=0.001347 bound=204.088760\n",
      "First hit for audio 38 at iteration 99\n",
      "It's way over 0.10090369415283203\n",
      "Worked i=39 loss=0.001722 bound=181.626648\n",
      "First hit for audio 39 at iteration 99\n",
      "It's way over 0.11006758880615235\n",
      "Worked i=40 loss=0.001404 bound=198.121674\n",
      "First hit for audio 40 at iteration 99\n",
      "It's way over 0.1079137191772461\n",
      "Worked i=41 loss=0.002708 bound=194.244705\n",
      "First hit for audio 41 at iteration 99\n",
      "It's way over 0.1113415756225586\n",
      "Worked i=42 loss=0.001491 bound=200.414841\n",
      "First hit for audio 42 at iteration 99\n",
      "It's way over 0.10411497497558594\n",
      "Worked i=43 loss=0.001553 bound=187.406952\n",
      "First hit for audio 43 at iteration 99\n",
      "It's way over 0.09991424560546874\n",
      "Worked i=44 loss=0.001446 bound=179.845642\n",
      "First hit for audio 44 at iteration 99\n",
      "It's way over 0.14311558532714844\n",
      "Worked i=45 loss=0.005083 bound=257.608063\n",
      "First hit for audio 45 at iteration 99\n",
      "It's way over 0.09499127960205078\n",
      "Worked i=46 loss=0.002263 bound=170.984314\n",
      "First hit for audio 46 at iteration 99\n",
      "It's way over 0.09834024047851563\n",
      "Worked i=47 loss=0.000956 bound=177.012451\n",
      "First hit for audio 47 at iteration 99\n",
      "It's way over 0.11358003997802735\n",
      "Worked i=48 loss=0.004408 bound=204.444077\n",
      "First hit for audio 48 at iteration 99\n",
      "It's way over 0.07897819519042969\n",
      "Worked i=49 loss=0.000863 bound=142.160751\n",
      "First hit for audio 49 at iteration 99\n",
      "It's way over 0.08756748199462891\n",
      "Worked i=50 loss=0.001402 bound=157.621460\n",
      "First hit for audio 50 at iteration 99\n",
      "It's way over 0.07577739715576172\n",
      "Worked i=51 loss=0.000712 bound=136.399307\n",
      "First hit for audio 51 at iteration 99\n",
      "It's way over 0.12669345092773437\n",
      "Worked i=52 loss=0.001656 bound=228.048218\n",
      "First hit for audio 52 at iteration 99\n",
      "It's way over 0.12099623870849609\n",
      "Worked i=53 loss=0.000957 bound=217.793228\n",
      "First hit for audio 53 at iteration 99\n",
      "It's way over 0.0955986557006836\n",
      "Worked i=54 loss=0.000872 bound=172.077576\n",
      "First hit for audio 54 at iteration 99\n",
      "It's way over 0.08841287231445312\n",
      "Worked i=55 loss=0.001151 bound=159.143173\n",
      "First hit for audio 55 at iteration 99\n",
      "It's way over 0.09893333435058593\n",
      "Worked i=56 loss=0.000849 bound=178.079987\n",
      "First hit for audio 56 at iteration 99\n",
      "It's way over 0.12172183990478516\n",
      "Worked i=57 loss=0.005600 bound=219.099319\n",
      "First hit for audio 57 at iteration 99\n",
      "It's way over 0.08805282592773438\n",
      "Worked i=58 loss=0.000640 bound=158.495087\n",
      "First hit for audio 58 at iteration 99\n",
      "It's way over 0.13028593444824219\n",
      "Worked i=59 loss=0.002952 bound=234.514679\n",
      "First hit for audio 59 at iteration 99\n",
      "It's way over 0.0859910888671875\n",
      "Worked i=60 loss=0.001748 bound=154.783966\n",
      "First hit for audio 60 at iteration 99\n",
      "It's way over 0.08608729553222656\n",
      "Worked i=61 loss=0.001505 bound=154.957138\n",
      "First hit for audio 61 at iteration 99\n",
      "It's way over 0.08901220703125\n",
      "Worked i=62 loss=0.001612 bound=160.221970\n",
      "First hit for audio 62 at iteration 99\n",
      "It's way over 0.09395106506347656\n",
      "Worked i=63 loss=0.001267 bound=169.111908\n",
      "First hit for audio 63 at iteration 99\n",
      "It's way over 0.09784568786621094\n",
      "Worked i=64 loss=0.001370 bound=176.122238\n",
      "First hit for audio 64 at iteration 99\n",
      "It's way over 0.1089378662109375\n",
      "Worked i=65 loss=0.001148 bound=196.088165\n",
      "First hit for audio 65 at iteration 99\n",
      "It's way over 0.07820864105224609\n",
      "Worked i=66 loss=0.002004 bound=140.775543\n",
      "First hit for audio 66 at iteration 99\n",
      "It's way over 0.10479939270019531\n",
      "Worked i=67 loss=0.001430 bound=188.638901\n",
      "First hit for audio 67 at iteration 99\n",
      "It's way over 0.0768973159790039\n",
      "Worked i=68 loss=0.000550 bound=138.415176\n",
      "First hit for audio 68 at iteration 99\n",
      "It's way over 0.11875457000732421\n",
      "Worked i=69 loss=0.000730 bound=213.758224\n",
      "First hit for audio 69 at iteration 99\n",
      "It's way over 0.10757159423828125\n",
      "Worked i=70 loss=0.000998 bound=193.628876\n",
      "First hit for audio 70 at iteration 99\n",
      "It's way over 0.1013489990234375\n",
      "Worked i=71 loss=0.002015 bound=182.428192\n",
      "First hit for audio 71 at iteration 99\n",
      "It's way over 0.09048123168945313\n",
      "Worked i=72 loss=0.001950 bound=162.866211\n",
      "First hit for audio 72 at iteration 99\n",
      "It's way over 0.0836833724975586\n",
      "Worked i=73 loss=0.002053 bound=150.630066\n",
      "First hit for audio 73 at iteration 99\n",
      "It's way over 0.09499562835693359\n",
      "Worked i=74 loss=0.002029 bound=170.992126\n",
      "First hit for audio 74 at iteration 99\n",
      "It's way over 0.08420903015136719\n",
      "Worked i=75 loss=0.000641 bound=151.576248\n",
      "First hit for audio 75 at iteration 99\n",
      "It's way over 0.09362613677978515\n",
      "Worked i=76 loss=0.000777 bound=168.527039\n",
      "First hit for audio 76 at iteration 99\n",
      "It's way over 0.12784565734863282\n",
      "Worked i=77 loss=0.002685 bound=230.122192\n",
      "First hit for audio 77 at iteration 99\n",
      "It's way over 0.08728205108642578\n",
      "Worked i=78 loss=0.002936 bound=157.107697\n",
      "First hit for audio 78 at iteration 99\n",
      "It's way over 0.10333242034912109\n",
      "Worked i=79 loss=0.000717 bound=185.998367\n",
      "First hit for audio 79 at iteration 99\n",
      "It's way over 0.08042650604248047\n",
      "Worked i=80 loss=0.001186 bound=144.767715\n",
      "First hit for audio 80 at iteration 99\n",
      "It's way over 0.11391829681396484\n",
      "Worked i=81 loss=0.000913 bound=205.052948\n",
      "First hit for audio 81 at iteration 99\n",
      "It's way over 0.0745837173461914\n",
      "Worked i=82 loss=0.000603 bound=134.250687\n",
      "First hit for audio 82 at iteration 99\n",
      "It's way over 0.1304532470703125\n",
      "Worked i=83 loss=0.002780 bound=234.815842\n",
      "First hit for audio 83 at iteration 99\n",
      "It's way over 0.09861420440673828\n",
      "Worked i=84 loss=0.000871 bound=177.505569\n",
      "First hit for audio 84 at iteration 99\n",
      "It's way over 0.10265802764892579\n",
      "Worked i=85 loss=0.001303 bound=184.784439\n",
      "First hit for audio 85 at iteration 99\n",
      "It's way over 0.09837681579589844\n",
      "Worked i=86 loss=0.000614 bound=177.078278\n",
      "First hit for audio 86 at iteration 99\n",
      "It's way over 0.08505178833007812\n",
      "Worked i=87 loss=0.002243 bound=153.093216\n",
      "First hit for audio 87 at iteration 99\n",
      "It's way over 0.10537099456787109\n",
      "Worked i=88 loss=0.000996 bound=189.667786\n",
      "First hit for audio 88 at iteration 99\n",
      "It's way over 0.12741154479980468\n",
      "Worked i=89 loss=0.004728 bound=229.340775\n",
      "First hit for audio 89 at iteration 99\n",
      "It's way over 0.11783087921142578\n",
      "Worked i=90 loss=0.000756 bound=212.095581\n",
      "First hit for audio 90 at iteration 99\n",
      "It's way over 0.07983795166015625\n",
      "Worked i=91 loss=0.000995 bound=143.708298\n",
      "First hit for audio 91 at iteration 99\n",
      "It's way over 0.13576148986816405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worked i=92 loss=0.002689 bound=244.370667\n",
      "First hit for audio 92 at iteration 99\n",
      "It's way over 0.09946486663818359\n",
      "Worked i=93 loss=0.001368 bound=179.036758\n",
      "First hit for audio 93 at iteration 99\n",
      "It's way over 0.15608955383300782\n",
      "Worked i=94 loss=0.002722 bound=280.961212\n",
      "First hit for audio 94 at iteration 99\n",
      "It's way over 0.09402879333496093\n",
      "Worked i=95 loss=0.001082 bound=169.251831\n",
      "First hit for audio 95 at iteration 99\n",
      "It's way over 0.11024378204345703\n",
      "Worked i=96 loss=0.003408 bound=198.438812\n",
      "First hit for audio 96 at iteration 99\n",
      "It's way over 0.12061452484130859\n",
      "Worked i=97 loss=0.001150 bound=217.106140\n",
      "First hit for audio 97 at iteration 99\n",
      "It's way over 0.10313349914550782\n",
      "Worked i=98 loss=0.002383 bound=185.640305\n",
      "First hit for audio 98 at iteration 99\n",
      "It's way over 0.09427326965332031\n",
      "Worked i=99 loss=0.001629 bound=169.691895\n",
      "First hit for audio 99 at iteration 99\n",
      "It's way over 0.08750263977050782\n",
      "Worked i=100 loss=0.001408 bound=157.504745\n",
      "First hit for audio 100 at iteration 99\n",
      "It's way over 0.08563699340820312\n",
      "Worked i=101 loss=0.003464 bound=154.146591\n",
      "First hit for audio 101 at iteration 99\n",
      "It's way over 0.10786285400390624\n",
      "Worked i=102 loss=0.000611 bound=194.153137\n",
      "First hit for audio 102 at iteration 99\n",
      "It's way over 0.11085428619384766\n",
      "Worked i=103 loss=0.000972 bound=199.537704\n",
      "First hit for audio 103 at iteration 99\n",
      "It's way over 0.09215826416015625\n",
      "Worked i=104 loss=0.005570 bound=165.884888\n",
      "First hit for audio 104 at iteration 99\n",
      "It's way over 0.08886624908447266\n",
      "Worked i=105 loss=0.000969 bound=159.959244\n",
      "First hit for audio 105 at iteration 99\n",
      "It's way over 0.09447521209716797\n",
      "Worked i=106 loss=0.001811 bound=170.055374\n",
      "First hit for audio 106 at iteration 99\n",
      "It's way over 0.09878734588623046\n",
      "Worked i=107 loss=0.002500 bound=177.817230\n",
      "First hit for audio 107 at iteration 99\n",
      "It's way over 0.09764197540283204\n",
      "Worked i=108 loss=0.000708 bound=175.755554\n",
      "First hit for audio 108 at iteration 99\n",
      "It's way over 0.09006121826171876\n",
      "Worked i=109 loss=0.000905 bound=162.110199\n",
      "First hit for audio 109 at iteration 99\n",
      "It's way over 0.11805169677734376\n",
      "Worked i=110 loss=0.002518 bound=212.493057\n",
      "First hit for audio 110 at iteration 99\n",
      "It's way over 0.09523656463623047\n",
      "Worked i=111 loss=0.000486 bound=171.425812\n",
      "First hit for audio 111 at iteration 99\n",
      "It's way over 0.10019107055664063\n",
      "Worked i=112 loss=0.003495 bound=180.343933\n",
      "First hit for audio 112 at iteration 99\n",
      "It's way over 0.10572837829589844\n",
      "Worked i=113 loss=0.001855 bound=190.311096\n",
      "First hit for audio 113 at iteration 99\n",
      "It's way over 0.10592498016357423\n",
      "Worked i=114 loss=0.002302 bound=190.664963\n",
      "First hit for audio 114 at iteration 99\n",
      "It's way over 0.09228130340576172\n",
      "Worked i=115 loss=0.001008 bound=166.106339\n",
      "First hit for audio 115 at iteration 99\n",
      "It's way over 0.08597835540771484\n",
      "Worked i=116 loss=0.001402 bound=154.761047\n",
      "First hit for audio 116 at iteration 99\n",
      "It's way over 0.11898297119140624\n",
      "Worked i=117 loss=0.002536 bound=214.169357\n",
      "First hit for audio 117 at iteration 99\n",
      "It's way over 0.09144355010986328\n",
      "Worked i=118 loss=0.001006 bound=164.598389\n",
      "First hit for audio 118 at iteration 99\n",
      "It's way over 0.08692733001708984\n",
      "Worked i=119 loss=0.000584 bound=156.469193\n",
      "First hit for audio 119 at iteration 99\n",
      "It's way over 0.08540941619873046\n",
      "Worked i=120 loss=0.000943 bound=153.736954\n",
      "First hit for audio 120 at iteration 99\n",
      "It's way over 0.15084523010253906\n",
      "Worked i=121 loss=0.001404 bound=271.521423\n",
      "First hit for audio 121 at iteration 99\n",
      "It's way over 0.08957711029052734\n",
      "Worked i=122 loss=0.002009 bound=161.238785\n",
      "First hit for audio 122 at iteration 99\n",
      "It's way over 0.11534124755859375\n",
      "Worked i=123 loss=0.001134 bound=207.614243\n",
      "First hit for audio 123 at iteration 99\n",
      "It's way over 0.11212852478027344\n",
      "Worked i=124 loss=0.001315 bound=201.831345\n",
      "First hit for audio 124 at iteration 99\n",
      "It's way over 0.07887308502197266\n",
      "Worked i=125 loss=0.000416 bound=141.971542\n",
      "First hit for audio 125 at iteration 99\n",
      "It's way over 0.09007015991210937\n",
      "Worked i=126 loss=0.001027 bound=162.126282\n",
      "First hit for audio 126 at iteration 99\n",
      "It's way over 0.08775847625732422\n",
      "Worked i=127 loss=0.001145 bound=157.965256\n",
      "First hit for audio 127 at iteration 99\n",
      "adv_tmp/train\n",
      "adv_tmp/train/off\n",
      "6.670683145523071\n",
      "0 tf.Tensor(\n",
      "[0.06472564 0.06868048 0.13380115 0.09489993 0.04761107 0.1484881\n",
      " 0.32490158 0.07506762 0.15839434 0.07241906 0.07054552 0.11278486\n",
      " 0.05352478 0.1501663  0.04523466 0.05795718 0.07354399 0.04175307\n",
      " 0.26350394 0.03833825 0.16398512 0.05522393 0.12208712 0.28104165\n",
      " 0.04397098 0.16026117 0.04856893 0.0386592  0.13927491 0.02685532\n",
      " 0.08553302 0.06395089 0.15444927 0.14045693 0.15325055 0.05026541\n",
      " 0.12591061 0.10515047 0.21216412 0.03745264 0.15571868 0.3099006\n",
      " 0.19848488 0.3104585  0.07898515 0.03768835 0.05531553 0.04926242\n",
      " 0.06183595 0.10869905 0.06985797 0.09499891 0.0395198  0.04299238\n",
      " 0.06553664 0.2358936  0.03212392 0.2374151  0.26200426 0.10614239\n",
      " 0.03661922 0.11733587 0.18475279 0.15736626 0.12850682 0.10075018\n",
      " 0.18875307 0.3590507  0.08836168 0.09653849 0.11216402 0.33732778\n",
      " 0.05134531 0.15827487 0.21329238 0.11721013 0.19127907 0.42532358\n",
      " 0.05613588 0.16183406 0.07681658 0.22966672 0.13278107 0.10061695\n",
      " 0.06124353 0.06749324 0.30571702 0.10381044 0.3612243  0.02823734\n",
      " 0.23398224 0.06473625 0.07357411 0.10497972 0.07944703 0.09623354\n",
      " 0.20578179 0.07568362 0.1694127  0.03994919 0.11407549 0.3335755\n",
      " 0.06482206 0.08309289 0.19299978 0.26234698 0.19737032 0.14255911\n",
      " 0.15144096 0.09483195 0.08849415 0.05709542 0.1898542  0.10425156\n",
      " 0.15800375 0.0597345  0.07181824 0.07033876 0.04360826 0.08853409\n",
      " 0.13981624 0.18690649 0.16346483 0.095467   0.13483006 0.21959005\n",
      " 0.08138685 0.1410382 ], shape=(128,), dtype=float32) [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "It's way over 0.004881317615509033\n",
      "Worked i=0 loss=0.064726 bound=8.786372\n",
      "First hit for audio 0 at iteration 0\n",
      "It's way over 0.00481458568572998\n",
      "Worked i=1 loss=0.068680 bound=8.666255\n",
      "First hit for audio 1 at iteration 0\n",
      "It's way over 0.00483961009979248\n",
      "Worked i=2 loss=0.133801 bound=8.711299\n",
      "First hit for audio 2 at iteration 0\n",
      "It's way over 0.004884016513824463\n",
      "Worked i=3 loss=0.094900 bound=8.791229\n",
      "First hit for audio 3 at iteration 0\n",
      "It's way over 0.004873918533325195\n",
      "Worked i=4 loss=0.047611 bound=8.773053\n",
      "First hit for audio 4 at iteration 0\n",
      "It's way over 0.004877685546875\n",
      "Worked i=5 loss=0.148488 bound=8.779834\n",
      "First hit for audio 5 at iteration 0\n",
      "It's way over 0.004849271774291992\n",
      "Worked i=6 loss=0.324902 bound=8.728689\n",
      "First hit for audio 6 at iteration 0\n",
      "It's way over 0.004874936103820801\n",
      "Worked i=7 loss=0.075068 bound=8.774885\n",
      "First hit for audio 7 at iteration 0\n",
      "It's way over 0.004886300086975098\n",
      "Worked i=8 loss=0.158394 bound=8.795341\n",
      "First hit for audio 8 at iteration 0\n",
      "It's way over 0.004865250110626221\n",
      "Worked i=9 loss=0.072419 bound=8.757450\n",
      "First hit for audio 9 at iteration 0\n",
      "It's way over 0.004866507053375244\n",
      "Worked i=10 loss=0.070546 bound=8.759713\n",
      "First hit for audio 10 at iteration 0\n",
      "It's way over 0.004845491886138916\n",
      "Worked i=11 loss=0.112785 bound=8.721887\n",
      "First hit for audio 11 at iteration 0\n",
      "It's way over 0.004833822727203369\n",
      "Worked i=12 loss=0.053525 bound=8.700881\n",
      "First hit for audio 12 at iteration 0\n",
      "It's way over 0.004894843101501465\n",
      "Worked i=13 loss=0.150166 bound=8.810718\n",
      "First hit for audio 13 at iteration 0\n",
      "It's way over 0.004843271255493164\n",
      "Worked i=14 loss=0.045235 bound=8.717888\n",
      "First hit for audio 14 at iteration 0\n",
      "It's way over 0.004642985343933106\n",
      "Worked i=15 loss=0.057957 bound=8.357374\n",
      "First hit for audio 15 at iteration 0\n",
      "It's way over 0.004760789394378662\n",
      "Worked i=16 loss=0.073544 bound=8.569420\n",
      "First hit for audio 16 at iteration 0\n",
      "It's way over 0.004857963085174561\n",
      "Worked i=17 loss=0.041753 bound=8.744333\n",
      "First hit for audio 17 at iteration 0\n",
      "It's way over 0.004873673439025879\n",
      "Worked i=18 loss=0.263504 bound=8.772613\n",
      "First hit for audio 18 at iteration 0\n",
      "It's way over 0.004838694095611573\n",
      "Worked i=19 loss=0.038338 bound=8.709649\n",
      "First hit for audio 19 at iteration 0\n",
      "It's way over 0.0046659731864929195\n",
      "Worked i=20 loss=0.163985 bound=8.398751\n",
      "First hit for audio 20 at iteration 0\n",
      "It's way over 0.004764856815338135\n",
      "Worked i=21 loss=0.055224 bound=8.576742\n",
      "First hit for audio 21 at iteration 0\n",
      "It's way over 0.004814351558685303\n",
      "Worked i=22 loss=0.122087 bound=8.665833\n",
      "First hit for audio 22 at iteration 0\n",
      "It's way over 0.004825035572052002\n",
      "Worked i=23 loss=0.281042 bound=8.685063\n",
      "First hit for audio 23 at iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's way over 0.0048696470260620114\n",
      "Worked i=24 loss=0.043971 bound=8.765364\n",
      "First hit for audio 24 at iteration 0\n",
      "It's way over 0.004893187046051025\n",
      "Worked i=25 loss=0.160261 bound=8.807736\n",
      "First hit for audio 25 at iteration 0\n",
      "It's way over 0.004895169734954834\n",
      "Worked i=26 loss=0.048569 bound=8.811305\n",
      "First hit for audio 26 at iteration 0\n",
      "It's way over 0.00400291109085083\n",
      "Worked i=27 loss=0.038659 bound=7.205240\n",
      "First hit for audio 27 at iteration 0\n",
      "It's way over 0.004886565685272216\n",
      "Worked i=28 loss=0.139275 bound=8.795818\n",
      "First hit for audio 28 at iteration 0\n",
      "It's way over 0.0048508491516113285\n",
      "Worked i=29 loss=0.026855 bound=8.731528\n",
      "First hit for audio 29 at iteration 0\n",
      "It's way over 0.004853036403656006\n",
      "Worked i=30 loss=0.085533 bound=8.735465\n",
      "First hit for audio 30 at iteration 0\n",
      "It's way over 0.004895068168640136\n",
      "Worked i=31 loss=0.063951 bound=8.811123\n",
      "First hit for audio 31 at iteration 0\n",
      "It's way over 0.004892979145050049\n",
      "Worked i=32 loss=0.154449 bound=8.807363\n",
      "First hit for audio 32 at iteration 0\n",
      "It's way over 0.004823696136474609\n",
      "Worked i=33 loss=0.140457 bound=8.682653\n",
      "First hit for audio 33 at iteration 0\n",
      "It's way over 0.004870296955108643\n",
      "Worked i=34 loss=0.153251 bound=8.766535\n",
      "First hit for audio 34 at iteration 0\n",
      "It's way over 0.004827732563018799\n",
      "Worked i=35 loss=0.050265 bound=8.689919\n",
      "First hit for audio 35 at iteration 0\n",
      "It's way over 0.004875653266906739\n",
      "Worked i=36 loss=0.125911 bound=8.776175\n",
      "First hit for audio 36 at iteration 0\n",
      "It's way over 0.004854588985443115\n",
      "Worked i=37 loss=0.105150 bound=8.738259\n",
      "First hit for audio 37 at iteration 0\n",
      "It's way over 0.004596142768859863\n",
      "Worked i=38 loss=0.212164 bound=8.273057\n",
      "First hit for audio 38 at iteration 0\n",
      "It's way over 0.003981969594955444\n",
      "Worked i=39 loss=0.037453 bound=7.167546\n",
      "First hit for audio 39 at iteration 0\n",
      "It's way over 0.00487457275390625\n",
      "Worked i=40 loss=0.155719 bound=8.774230\n",
      "First hit for audio 40 at iteration 0\n",
      "It's way over 0.004887975215911865\n",
      "Worked i=41 loss=0.309901 bound=8.798355\n",
      "First hit for audio 41 at iteration 0\n",
      "It's way over 0.004899878025054932\n",
      "Worked i=42 loss=0.198485 bound=8.819780\n",
      "First hit for audio 42 at iteration 0\n",
      "It's way over 0.004694859981536865\n",
      "Worked i=43 loss=0.310459 bound=8.450748\n",
      "First hit for audio 43 at iteration 0\n",
      "It's way over 0.004892377376556396\n",
      "Worked i=44 loss=0.078985 bound=8.806279\n",
      "First hit for audio 44 at iteration 0\n",
      "It's way over 0.004616772174835205\n",
      "Worked i=45 loss=0.037688 bound=8.310190\n",
      "First hit for audio 45 at iteration 0\n",
      "It's way over 0.0048583860397338864\n",
      "Worked i=46 loss=0.055316 bound=8.745094\n",
      "First hit for audio 46 at iteration 0\n",
      "It's way over 0.004894826412200928\n",
      "Worked i=47 loss=0.049262 bound=8.810688\n",
      "First hit for audio 47 at iteration 0\n",
      "It's way over 0.004882716178894043\n",
      "Worked i=48 loss=0.061836 bound=8.788889\n",
      "First hit for audio 48 at iteration 0\n",
      "It's way over 0.004851258277893066\n",
      "Worked i=49 loss=0.108699 bound=8.732265\n",
      "First hit for audio 49 at iteration 0\n",
      "It's way over 0.004775541305541992\n",
      "Worked i=50 loss=0.069858 bound=8.595974\n",
      "First hit for audio 50 at iteration 0\n",
      "It's way over 0.004691572666168213\n",
      "Worked i=51 loss=0.094999 bound=8.444831\n",
      "First hit for audio 51 at iteration 0\n",
      "It's way over 0.004856791973114014\n",
      "Worked i=52 loss=0.039520 bound=8.742226\n",
      "First hit for audio 52 at iteration 0\n",
      "It's way over 0.004855899810791015\n",
      "Worked i=53 loss=0.042992 bound=8.740619\n",
      "First hit for audio 53 at iteration 0\n",
      "It's way over 0.004871145248413086\n",
      "Worked i=54 loss=0.065537 bound=8.768062\n",
      "First hit for audio 54 at iteration 0\n",
      "It's way over 0.004895954608917236\n",
      "Worked i=55 loss=0.235894 bound=8.812718\n",
      "First hit for audio 55 at iteration 0\n",
      "It's way over 0.004705184936523437\n",
      "Worked i=56 loss=0.032124 bound=8.469333\n",
      "First hit for audio 56 at iteration 0\n",
      "It's way over 0.0046437840461730955\n",
      "Worked i=57 loss=0.237415 bound=8.358811\n",
      "First hit for audio 57 at iteration 0\n",
      "It's way over 0.004898246288299561\n",
      "Worked i=58 loss=0.262004 bound=8.816844\n",
      "First hit for audio 58 at iteration 0\n",
      "It's way over 0.004841084003448486\n",
      "Worked i=59 loss=0.106142 bound=8.713951\n",
      "First hit for audio 59 at iteration 0\n",
      "It's way over 0.004105706691741943\n",
      "Worked i=60 loss=0.036619 bound=7.390272\n",
      "First hit for audio 60 at iteration 0\n",
      "It's way over 0.004898967266082764\n",
      "Worked i=61 loss=0.117336 bound=8.818141\n",
      "First hit for audio 61 at iteration 0\n",
      "It's way over 0.004841136455535889\n",
      "Worked i=62 loss=0.184753 bound=8.714046\n",
      "First hit for audio 62 at iteration 0\n",
      "It's way over 0.004832167148590088\n",
      "Worked i=63 loss=0.157366 bound=8.697901\n",
      "First hit for audio 63 at iteration 0\n",
      "It's way over 0.004896038055419922\n",
      "Worked i=64 loss=0.128507 bound=8.812869\n",
      "First hit for audio 64 at iteration 0\n",
      "It's way over 0.004862626552581787\n",
      "Worked i=65 loss=0.100750 bound=8.752728\n",
      "First hit for audio 65 at iteration 0\n",
      "It's way over 0.004889814853668213\n",
      "Worked i=66 loss=0.188753 bound=8.801666\n",
      "First hit for audio 66 at iteration 0\n",
      "It's way over 0.004731123924255371\n",
      "Worked i=67 loss=0.359051 bound=8.516023\n",
      "First hit for audio 67 at iteration 0\n",
      "It's way over 0.004881227970123291\n",
      "Worked i=68 loss=0.088362 bound=8.786210\n",
      "First hit for audio 68 at iteration 0\n",
      "It's way over 0.004846898555755616\n",
      "Worked i=69 loss=0.096538 bound=8.724418\n",
      "First hit for audio 69 at iteration 0\n",
      "It's way over 0.004839804649353028\n",
      "Worked i=70 loss=0.112164 bound=8.711648\n",
      "First hit for audio 70 at iteration 0\n",
      "It's way over 0.004879966259002686\n",
      "Worked i=71 loss=0.337328 bound=8.783939\n",
      "First hit for audio 71 at iteration 0\n",
      "It's way over 0.004860022068023682\n",
      "Worked i=72 loss=0.051345 bound=8.748039\n",
      "First hit for audio 72 at iteration 0\n",
      "It's way over 0.004897669792175293\n",
      "Worked i=73 loss=0.158275 bound=8.815805\n",
      "First hit for audio 73 at iteration 0\n",
      "It's way over 0.004897709369659424\n",
      "Worked i=74 loss=0.213292 bound=8.815877\n",
      "First hit for audio 74 at iteration 0\n",
      "It's way over 0.00488366174697876\n",
      "Worked i=75 loss=0.117210 bound=8.790592\n",
      "First hit for audio 75 at iteration 0\n",
      "It's way over 0.004871080398559571\n",
      "Worked i=76 loss=0.191279 bound=8.767944\n",
      "First hit for audio 76 at iteration 0\n",
      "It's way over 0.004776481628417969\n",
      "Worked i=77 loss=0.425324 bound=8.597667\n",
      "First hit for audio 77 at iteration 0\n",
      "It's way over 0.004866129875183105\n",
      "Worked i=78 loss=0.056136 bound=8.759034\n",
      "First hit for audio 78 at iteration 0\n",
      "It's way over 0.004852742671966553\n",
      "Worked i=79 loss=0.161834 bound=8.734937\n",
      "First hit for audio 79 at iteration 0\n",
      "It's way over 0.0047725577354431154\n",
      "Worked i=80 loss=0.076817 bound=8.590604\n",
      "First hit for audio 80 at iteration 0\n",
      "It's way over 0.004658846378326416\n",
      "Worked i=81 loss=0.229667 bound=8.385922\n",
      "First hit for audio 81 at iteration 0\n",
      "It's way over 0.004883386135101318\n",
      "Worked i=82 loss=0.132781 bound=8.790095\n",
      "First hit for audio 82 at iteration 0\n",
      "It's way over 0.00488488245010376\n",
      "Worked i=83 loss=0.100617 bound=8.792788\n",
      "First hit for audio 83 at iteration 0\n",
      "It's way over 0.004845697402954102\n",
      "Worked i=84 loss=0.061244 bound=8.722255\n",
      "First hit for audio 84 at iteration 0\n",
      "It's way over 0.004869935989379882\n",
      "Worked i=85 loss=0.067493 bound=8.765884\n",
      "First hit for audio 85 at iteration 0\n",
      "It's way over 0.0048308706283569335\n",
      "Worked i=86 loss=0.305717 bound=8.695567\n",
      "First hit for audio 86 at iteration 0\n",
      "It's way over 0.004889045715332031\n",
      "Worked i=87 loss=0.103810 bound=8.800282\n",
      "First hit for audio 87 at iteration 0\n",
      "It's way over 0.0048802499771118165\n",
      "Worked i=88 loss=0.361224 bound=8.784450\n",
      "First hit for audio 88 at iteration 0\n",
      "It's way over 0.004739259719848633\n",
      "Worked i=89 loss=0.028237 bound=8.530668\n",
      "First hit for audio 89 at iteration 0\n",
      "It's way over 0.004879670143127441\n",
      "Worked i=90 loss=0.233982 bound=8.783406\n",
      "First hit for audio 90 at iteration 0\n",
      "It's way over 0.0048510880470275875\n",
      "Worked i=91 loss=0.064736 bound=8.731958\n",
      "First hit for audio 91 at iteration 0\n",
      "It's way over 0.00470977258682251\n",
      "Worked i=92 loss=0.073574 bound=8.477591\n",
      "First hit for audio 92 at iteration 0\n",
      "It's way over 0.003798459768295288\n",
      "Worked i=93 loss=0.104980 bound=6.837227\n",
      "First hit for audio 93 at iteration 0\n",
      "It's way over 0.004157748699188233\n",
      "Worked i=94 loss=0.079447 bound=7.483948\n",
      "First hit for audio 94 at iteration 0\n",
      "It's way over 0.00485871171951294\n",
      "Worked i=95 loss=0.096234 bound=8.745682\n",
      "First hit for audio 95 at iteration 0\n",
      "It's way over 0.0048958945274353025\n",
      "Worked i=96 loss=0.205782 bound=8.812610\n",
      "First hit for audio 96 at iteration 0\n",
      "It's way over 0.004556562423706055\n",
      "Worked i=97 loss=0.075684 bound=8.201813\n",
      "First hit for audio 97 at iteration 0\n",
      "It's way over 0.004875361442565918\n",
      "Worked i=98 loss=0.169413 bound=8.775651\n",
      "First hit for audio 98 at iteration 0\n",
      "It's way over 0.004786614418029785\n",
      "Worked i=99 loss=0.039949 bound=8.615906\n",
      "First hit for audio 99 at iteration 0\n",
      "It's way over 0.0048478636741638185\n",
      "Worked i=100 loss=0.114075 bound=8.726154\n",
      "First hit for audio 100 at iteration 0\n",
      "It's way over 0.0048820672035217285\n",
      "Worked i=101 loss=0.333575 bound=8.787721\n",
      "First hit for audio 101 at iteration 0\n",
      "It's way over 0.004856038570404053\n",
      "Worked i=102 loss=0.064822 bound=8.740870\n",
      "First hit for audio 102 at iteration 0\n",
      "It's way over 0.004878295421600342\n",
      "Worked i=103 loss=0.083093 bound=8.780932\n",
      "First hit for audio 103 at iteration 0\n",
      "It's way over 0.004880372047424316\n",
      "Worked i=104 loss=0.193000 bound=8.784670\n",
      "First hit for audio 104 at iteration 0\n",
      "It's way over 0.0047263941764831546\n",
      "Worked i=105 loss=0.262347 bound=8.507510\n",
      "First hit for audio 105 at iteration 0\n",
      "It's way over 0.004880893230438233\n",
      "Worked i=106 loss=0.197370 bound=8.785607\n",
      "First hit for audio 106 at iteration 0\n",
      "It's way over 0.004894073963165283\n",
      "Worked i=107 loss=0.142559 bound=8.809334\n",
      "First hit for audio 107 at iteration 0\n",
      "It's way over 0.004887106418609619\n",
      "Worked i=108 loss=0.151441 bound=8.796791\n",
      "First hit for audio 108 at iteration 0\n",
      "It's way over 0.004824140548706055\n",
      "Worked i=109 loss=0.094832 bound=8.683454\n",
      "First hit for audio 109 at iteration 0\n",
      "It's way over 0.0046610236167907715\n",
      "Worked i=110 loss=0.088494 bound=8.389843\n",
      "First hit for audio 110 at iteration 0\n",
      "It's way over 0.004741656303405762\n",
      "Worked i=111 loss=0.057095 bound=8.534981\n",
      "First hit for audio 111 at iteration 0\n",
      "It's way over 0.004887801647186279\n",
      "Worked i=112 loss=0.189854 bound=8.798043\n",
      "First hit for audio 112 at iteration 0\n",
      "It's way over 0.004830483913421631\n",
      "Worked i=113 loss=0.104252 bound=8.694870\n",
      "First hit for audio 113 at iteration 0\n",
      "It's way over 0.004888913154602051\n",
      "Worked i=114 loss=0.158004 bound=8.800044\n",
      "First hit for audio 114 at iteration 0\n",
      "It's way over 0.004794262886047364\n",
      "Worked i=115 loss=0.059735 bound=8.629673\n",
      "First hit for audio 115 at iteration 0\n",
      "It's way over 0.004868345737457275\n",
      "Worked i=116 loss=0.071818 bound=8.763022\n",
      "First hit for audio 116 at iteration 0\n",
      "It's way over 0.004851105690002441\n",
      "Worked i=117 loss=0.070339 bound=8.731990\n",
      "First hit for audio 117 at iteration 0\n",
      "It's way over 0.0031667473316192626\n",
      "Worked i=118 loss=0.043608 bound=5.700145\n",
      "First hit for audio 118 at iteration 0\n",
      "It's way over 0.004679359436035156\n",
      "Worked i=119 loss=0.088534 bound=8.422847\n",
      "First hit for audio 119 at iteration 0\n",
      "It's way over 0.004895582675933838\n",
      "Worked i=120 loss=0.139816 bound=8.812050\n",
      "First hit for audio 120 at iteration 0\n",
      "It's way over 0.004861606597900391\n",
      "Worked i=121 loss=0.186906 bound=8.750893\n",
      "First hit for audio 121 at iteration 0\n",
      "It's way over 0.0048946461677551265\n",
      "Worked i=122 loss=0.163465 bound=8.810364\n",
      "First hit for audio 122 at iteration 0\n",
      "It's way over 0.004721129417419433\n",
      "Worked i=123 loss=0.095467 bound=8.498033\n",
      "First hit for audio 123 at iteration 0\n",
      "It's way over 0.0048852009773254395\n",
      "Worked i=124 loss=0.134830 bound=8.793362\n",
      "First hit for audio 124 at iteration 0\n",
      "It's way over 0.0048393535614013675\n",
      "Worked i=125 loss=0.219590 bound=8.710837\n",
      "First hit for audio 125 at iteration 0\n",
      "It's way over 0.004884975433349609\n",
      "Worked i=126 loss=0.081387 bound=8.792955\n",
      "First hit for audio 126 at iteration 0\n",
      "It's way over 0.004887275218963623\n",
      "Worked i=127 loss=0.141038 bound=8.797096\n",
      "First hit for audio 127 at iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_tmp/train \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of total examples: 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 355/355 [00:06<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Train data shape: (355, 16000, 1), adv train label shape: (355,)\n",
      "adversarial train data uploaded\n",
      "Attack finished for training\n",
      "attack time1219.9937250614166\n",
      " Adversarial training completed for 1 iteration\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 0, Adv Train: Loss: 1.2922433614730835, acc: 46.32523159186046\n",
      "Epoch: 0, Val: Loss: 1.1609889268875122, acc: 50.0\n",
      "Epoch: 1, Train: Loss: 1.0068423748016357, acc: 52.795252203941345\n",
      "Epoch: 1, Val: Loss: 0.7305306792259216, acc: 50.0\n",
      "Epoch: 2, Train: Loss: 0.6923967599868774, acc: 59.03003215789795\n",
      "Epoch: 2, Val: Loss: 0.7223976850509644, acc: 50.0\n",
      "Epoch: 3, Train: Loss: 0.7655476033687592, acc: 49.80215132236481\n",
      "Epoch: 3, Val: Loss: 0.7966258525848389, acc: 50.0\n",
      "Epoch: 4, Train: Loss: 0.7906105220317841, acc: 49.80215132236481\n",
      "Epoch: 4, Val: Loss: 0.712687075138092, acc: 50.0\n",
      "Epoch: 5, Train: Loss: 0.6987673342227936, acc: 49.80215132236481\n",
      "Epoch: 5, Val: Loss: 0.6627698540687561, acc: 80.7692289352417\n",
      "Epoch: 6, Train: Loss: 0.6660720705986023, acc: 56.56960308551788\n",
      "Epoch: 6, Val: Loss: 0.6980201005935669, acc: 50.0\n",
      "Epoch: 7, Train: Loss: 0.6934482157230377, acc: 54.09902632236481\n",
      "Epoch: 7, Val: Loss: 0.7191159129142761, acc: 50.0\n",
      "Epoch: 8, Train: Loss: 0.6924873888492584, acc: 55.78835308551788\n",
      "Epoch: 8, Val: Loss: 0.6909652352333069, acc: 50.0\n",
      "Epoch: 9, Train: Loss: 0.6558829545974731, acc: 56.69642984867096\n",
      "Epoch: 9, Val: Loss: 0.6581916213035583, acc: 50.0\n",
      "Epoch: 10, Train: Loss: 0.6335230767726898, acc: 68.25791299343109\n",
      "Epoch: 10, Val: Loss: 0.654603123664856, acc: 69.2307710647583\n",
      "Epoch: 11, Train: Loss: 0.6382961869239807, acc: 57.86830484867096\n",
      "Epoch: 11, Val: Loss: 0.6594418883323669, acc: 53.84615659713745\n",
      "Epoch: 12, Train: Loss: 0.6392994821071625, acc: 56.56452775001526\n",
      "Epoch: 12, Val: Loss: 0.6506065726280212, acc: 69.2307710647583\n",
      "Epoch: 13, Train: Loss: 0.6221798658370972, acc: 65.13798832893372\n",
      "Epoch: 13, Val: Loss: 0.6395405530929565, acc: 84.61538553237915\n",
      "Epoch: 14, Train: Loss: 0.6024534106254578, acc: 71.90036475658417\n",
      "Epoch: 14, Val: Loss: 0.6425608992576599, acc: 50.0\n",
      "Epoch: 15, Train: Loss: 0.5926490426063538, acc: 66.96428656578064\n",
      "Epoch: 15, Val: Loss: 0.6517091989517212, acc: 50.0\n",
      "Epoch: 16, Train: Loss: 0.5829012393951416, acc: 65.66051244735718\n",
      "Epoch: 16, Val: Loss: 0.6526550650596619, acc: 50.0\n",
      "Epoch: 17, Train: Loss: 0.5645305514335632, acc: 68.91233623027802\n",
      "Epoch: 17, Val: Loss: 0.6467951536178589, acc: 65.38461446762085\n",
      "Epoch: 18, Train: Loss: 0.5460040122270584, acc: 72.42288887500763\n",
      "Epoch: 18, Val: Loss: 0.6396685242652893, acc: 80.7692289352417\n",
      "Epoch: 19, Train: Loss: 0.5307535976171494, acc: 75.15219151973724\n",
      "Epoch: 19, Val: Loss: 0.6298671960830688, acc: 80.7692289352417\n",
      "Epoch: 20, Train: Loss: 0.5072253793478012, acc: 76.32406651973724\n",
      "Epoch: 20, Val: Loss: 0.6208524107933044, acc: 80.7692289352417\n",
      "Epoch: 21, Train: Loss: 0.48011960089206696, acc: 78.27719151973724\n",
      "Epoch: 21, Val: Loss: 0.6208111047744751, acc: 80.7692289352417\n",
      "Epoch: 22, Train: Loss: 0.45285531878471375, acc: 79.05844151973724\n",
      "Epoch: 22, Val: Loss: 0.6294984817504883, acc: 84.61538553237915\n",
      "Epoch: 23, Train: Loss: 0.41995568573474884, acc: 82.56899416446686\n",
      "Epoch: 23, Val: Loss: 0.6468914747238159, acc: 80.7692289352417\n",
      "Epoch: 24, Train: Loss: 0.3855380415916443, acc: 82.17836916446686\n",
      "Epoch: 24, Val: Loss: 0.6374691724777222, acc: 76.92307829856873\n",
      "Epoch: 25, Train: Loss: 0.34787701070308685, acc: 85.68892180919647\n",
      "Epoch: 25, Val: Loss: 0.6297197341918945, acc: 80.7692289352417\n",
      "Epoch: 26, Train: Loss: 0.3122773915529251, acc: 87.63697147369385\n",
      "Epoch: 26, Val: Loss: 0.6528283357620239, acc: 76.92307829856873\n",
      "Epoch: 27, Train: Loss: 0.28372351825237274, acc: 89.06757235527039\n",
      "Epoch: 27, Val: Loss: 0.6219151020050049, acc: 80.7692289352417\n",
      "Epoch: 28, Train: Loss: 0.24848925322294235, acc: 90.63007235527039\n",
      "Epoch: 28, Val: Loss: 0.6233392953872681, acc: 80.7692289352417\n",
      "Epoch: 29, Train: Loss: 0.21723942086100578, acc: 91.02069735527039\n",
      "Epoch: 29, Val: Loss: 0.6322879195213318, acc: 80.7692289352417\n",
      "Epoch: 30, Train: Loss: 0.17609355971217155, acc: 93.10064911842346\n",
      "Epoch: 30, Val: Loss: 0.8011900186538696, acc: 73.07692170143127\n",
      "Epoch: 31, Train: Loss: 0.16109291836619377, acc: 94.66314911842346\n",
      "Epoch: 31, Val: Loss: 0.7491769194602966, acc: 69.2307710647583\n",
      "Epoch: 32, Train: Loss: 0.12126634456217289, acc: 95.3125\n",
      "Epoch: 32, Val: Loss: 0.9934202432632446, acc: 61.538463830947876\n",
      "Epoch: 33, Train: Loss: 0.09507539588958025, acc: 97.65625\n",
      "Epoch: 33, Val: Loss: 0.870474100112915, acc: 76.92307829856873\n",
      "Epoch: 34, Train: Loss: 0.08590817544609308, acc: 97.39752411842346\n",
      "Epoch: 34, Val: Loss: 1.0253084897994995, acc: 73.07692170143127\n",
      "Epoch: 35, Train: Loss: 0.33984698355197906, acc: 92.46144592761993\n",
      "Epoch: 35, Val: Loss: 1.072526216506958, acc: 69.2307710647583\n",
      "Epoch: 36, Train: Loss: 0.33444221317768097, acc: 93.49634647369385\n",
      "Epoch: 36, Val: Loss: 0.9851782917976379, acc: 69.2307710647583\n",
      "Epoch: 37, Train: Loss: 0.3673000782728195, acc: 92.71509647369385\n",
      "Epoch: 37, Val: Loss: 1.1696442365646362, acc: 73.07692170143127\n",
      "Epoch: 38, Train: Loss: 0.5143844187259674, acc: 88.42329680919647\n",
      "Epoch: 38, Val: Loss: 0.6604928970336914, acc: 80.7692289352417\n",
      "Epoch: 39, Train: Loss: 0.34832319617271423, acc: 89.59517180919647\n",
      "Epoch: 39, Val: Loss: 0.5917928218841553, acc: 80.7692289352417\n",
      "Epoch: 40, Train: Loss: 0.3564392328262329, acc: 86.07954680919647\n",
      "Epoch: 40, Val: Loss: 0.5074800848960876, acc: 88.46153616905212\n",
      "Epoch: 41, Train: Loss: 0.29674308747053146, acc: 89.07264471054077\n",
      "Epoch: 41, Val: Loss: 0.5103189945220947, acc: 76.92307829856873\n",
      "Epoch: 42, Train: Loss: 0.3100201189517975, acc: 89.46326971054077\n",
      "Epoch: 42, Val: Loss: 0.5086740255355835, acc: 73.07692170143127\n",
      "Epoch: 43, Train: Loss: 0.2983432114124298, acc: 89.72199559211731\n",
      "Epoch: 43, Val: Loss: 0.47672131657600403, acc: 84.61538553237915\n",
      "Epoch: 44, Train: Loss: 0.26250534504652023, acc: 92.06574559211731\n",
      "Epoch: 44, Val: Loss: 0.48030996322631836, acc: 84.61538553237915\n",
      "Epoch: 45, Train: Loss: 0.24475712329149246, acc: 91.28449559211731\n",
      "Epoch: 45, Val: Loss: 0.4990396201610565, acc: 84.61538553237915\n",
      "Epoch: 46, Train: Loss: 0.21370746940374374, acc: 93.10572147369385\n",
      "Epoch: 46, Val: Loss: 0.5165661573410034, acc: 88.46153616905212\n",
      "Epoch: 47, Train: Loss: 0.17711710184812546, acc: 94.53632235527039\n",
      "Epoch: 47, Val: Loss: 0.5578885674476624, acc: 84.61538553237915\n",
      "Epoch: 48, Train: Loss: 0.16036668047308922, acc: 93.75507235527039\n",
      "Epoch: 48, Val: Loss: 0.5890291333198547, acc: 84.61538553237915\n",
      "Epoch: 49, Train: Loss: 0.1305123157799244, acc: 95.96692323684692\n",
      "Epoch: 49, Val: Loss: 0.6264451742172241, acc: 80.7692289352417\n",
      "Epoch: 50, Train: Loss: 0.11322961747646332, acc: 96.61627411842346\n",
      "Epoch: 50, Val: Loss: 0.6800469756126404, acc: 80.7692289352417\n",
      "Epoch: 51, Train: Loss: 0.10233507677912712, acc: 97.00689911842346\n",
      "Epoch: 51, Val: Loss: 0.7310001850128174, acc: 80.7692289352417\n",
      "Epoch: 52, Train: Loss: 0.09239295497536659, acc: 97.39752411842346\n",
      "Epoch: 52, Val: Loss: 0.7803353667259216, acc: 80.7692289352417\n",
      "Epoch: 53, Train: Loss: 0.084193866699934, acc: 98.046875\n",
      "Epoch: 53, Val: Loss: 0.8518475294113159, acc: 80.7692289352417\n",
      "Epoch: 54, Train: Loss: 0.07476709689944983, acc: 98.046875\n",
      "Epoch: 54, Val: Loss: 0.9910592436790466, acc: 73.07692170143127\n",
      "Epoch: 55, Train: Loss: 0.0686840726993978, acc: 98.4375\n",
      "Epoch: 55, Val: Loss: 1.1055697202682495, acc: 69.2307710647583\n",
      "Epoch: 56, Train: Loss: 0.06554010231047869, acc: 98.828125\n",
      "Epoch: 56, Val: Loss: 1.0847265720367432, acc: 73.07692170143127\n",
      "Epoch: 57, Train: Loss: 0.06162486458197236, acc: 98.828125\n",
      "Epoch: 57, Val: Loss: 1.0389630794525146, acc: 73.07692170143127\n",
      "Epoch: 58, Train: Loss: 0.059817831963300705, acc: 98.828125\n",
      "Epoch: 58, Val: Loss: 1.0494282245635986, acc: 73.07692170143127\n",
      "Epoch: 59, Train: Loss: 0.05658131558448076, acc: 98.828125\n",
      "Epoch: 59, Val: Loss: 1.0214345455169678, acc: 73.07692170143127\n",
      "Epoch: 60, Train: Loss: 0.05304837878793478, acc: 98.828125\n",
      "Epoch: 60, Val: Loss: 0.9758238196372986, acc: 76.92307829856873\n",
      "Epoch: 61, Train: Loss: 0.049073010217398405, acc: 98.828125\n",
      "Epoch: 61, Val: Loss: 0.939208984375, acc: 76.92307829856873\n",
      "Epoch: 62, Train: Loss: 0.042597840540111065, acc: 98.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Val: Loss: 0.9116320013999939, acc: 84.61538553237915\n",
      "Epoch: 63, Train: Loss: 0.03519463213160634, acc: 99.21875\n",
      "Epoch: 63, Val: Loss: 0.9085296392440796, acc: 84.61538553237915\n",
      "Epoch: 64, Train: Loss: 0.02838753303512931, acc: 99.609375\n",
      "Epoch: 64, Val: Loss: 0.9022642374038696, acc: 84.61538553237915\n",
      "Epoch: 65, Train: Loss: 0.02636163868010044, acc: 99.609375\n",
      "Epoch: 65, Val: Loss: 0.9131265878677368, acc: 84.61538553237915\n",
      "Epoch: 66, Train: Loss: 0.025304353563115, acc: 99.609375\n",
      "Epoch: 66, Val: Loss: 0.9288522005081177, acc: 84.61538553237915\n",
      "Epoch: 67, Train: Loss: 0.023933509131893516, acc: 99.609375\n",
      "Epoch: 67, Val: Loss: 0.9436384439468384, acc: 84.61538553237915\n",
      "Epoch: 68, Train: Loss: 0.022739429958164692, acc: 99.609375\n",
      "Epoch: 68, Val: Loss: 0.9576337337493896, acc: 84.61538553237915\n",
      "Epoch: 69, Train: Loss: 0.0222885818220675, acc: 99.609375\n",
      "Epoch: 69, Val: Loss: 0.9701334834098816, acc: 84.61538553237915\n",
      "Epoch: 70, Train: Loss: 0.02205171051900834, acc: 99.609375\n",
      "Epoch: 70, Val: Loss: 0.9804683923721313, acc: 84.61538553237915\n",
      "Epoch: 71, Train: Loss: 0.0218595884507522, acc: 99.609375\n",
      "Epoch: 71, Val: Loss: 0.9882921576499939, acc: 84.61538553237915\n",
      "Epoch: 72, Train: Loss: 0.021664995467290282, acc: 99.609375\n",
      "Epoch: 72, Val: Loss: 0.9935225248336792, acc: 84.61538553237915\n",
      "Epoch: 73, Train: Loss: 0.021451262175105512, acc: 99.609375\n",
      "Epoch: 73, Val: Loss: 0.9962711334228516, acc: 84.61538553237915\n",
      "Epoch: 74, Train: Loss: 0.021214066189713776, acc: 99.609375\n",
      "Epoch: 74, Val: Loss: 0.9967883825302124, acc: 84.61538553237915\n",
      "Epoch: 75, Train: Loss: 0.02095478039700538, acc: 99.609375\n",
      "Epoch: 75, Val: Loss: 0.9954166412353516, acc: 84.61538553237915\n",
      "Epoch: 76, Train: Loss: 0.020677446154877543, acc: 99.609375\n",
      "Epoch: 76, Val: Loss: 0.9925459623336792, acc: 84.61538553237915\n",
      "Epoch: 77, Train: Loss: 0.020387170952744782, acc: 99.609375\n",
      "Epoch: 77, Val: Loss: 0.9885818958282471, acc: 84.61538553237915\n",
      "Epoch: 78, Train: Loss: 0.020089211291633546, acc: 99.609375\n",
      "Epoch: 78, Val: Loss: 0.9839219450950623, acc: 84.61538553237915\n",
      "Epoch: 79, Train: Loss: 0.019788292236626148, acc: 99.609375\n",
      "Epoch: 79, Val: Loss: 0.9789440631866455, acc: 84.61538553237915\n",
      "Epoch: 80, Train: Loss: 0.019488006830215454, acc: 99.609375\n",
      "Epoch: 80, Val: Loss: 0.9739975333213806, acc: 84.61538553237915\n",
      "Epoch: 81, Train: Loss: 0.01919042458757758, acc: 99.609375\n",
      "Epoch: 81, Val: Loss: 0.9693955183029175, acc: 84.61538553237915\n",
      "Epoch: 82, Train: Loss: 0.018895795103162527, acc: 99.609375\n",
      "Epoch: 82, Val: Loss: 0.9654093980789185, acc: 84.61538553237915\n",
      "Epoch: 83, Train: Loss: 0.018602591706439853, acc: 99.609375\n",
      "Epoch: 83, Val: Loss: 0.9622599482536316, acc: 84.61538553237915\n",
      "Epoch: 84, Train: Loss: 0.01830783160403371, acc: 99.609375\n",
      "Epoch: 84, Val: Loss: 0.9601144194602966, acc: 84.61538553237915\n",
      "Epoch: 85, Train: Loss: 0.018007624428719282, acc: 99.609375\n",
      "Epoch: 85, Val: Loss: 0.9590796828269958, acc: 84.61538553237915\n",
      "Epoch: 86, Train: Loss: 0.01769777061417699, acc: 99.609375\n",
      "Epoch: 86, Val: Loss: 0.9592002034187317, acc: 84.61538553237915\n",
      "Epoch: 87, Train: Loss: 0.017374221701174974, acc: 99.609375\n",
      "Epoch: 87, Val: Loss: 0.9604594111442566, acc: 84.61538553237915\n",
      "Epoch: 88, Train: Loss: 0.017033433075994253, acc: 99.609375\n",
      "Epoch: 88, Val: Loss: 0.9627843499183655, acc: 84.61538553237915\n",
      "Epoch: 89, Train: Loss: 0.016672705300152302, acc: 99.609375\n",
      "Epoch: 89, Val: Loss: 0.9660549163818359, acc: 84.61538553237915\n",
      "Epoch: 90, Train: Loss: 0.016289882361888885, acc: 99.609375\n",
      "Epoch: 90, Val: Loss: 0.9701206684112549, acc: 84.61538553237915\n",
      "Epoch: 91, Train: Loss: 0.01588275656104088, acc: 99.609375\n",
      "Epoch: 91, Val: Loss: 0.9748191833496094, acc: 84.61538553237915\n",
      "Epoch: 92, Train: Loss: 0.015448593767359853, acc: 99.609375\n",
      "Epoch: 92, Val: Loss: 0.9799947738647461, acc: 84.61538553237915\n",
      "Epoch: 93, Train: Loss: 0.01498801726847887, acc: 99.609375\n",
      "Epoch: 93, Val: Loss: 0.9854655861854553, acc: 84.61538553237915\n",
      "Epoch: 94, Train: Loss: 0.014472669223323464, acc: 99.609375\n",
      "Epoch: 94, Val: Loss: 0.9911719560623169, acc: 84.61538553237915\n",
      "Epoch: 95, Train: Loss: 0.013920081313699484, acc: 99.609375\n",
      "Epoch: 95, Val: Loss: 0.99717777967453, acc: 84.61538553237915\n",
      "Epoch: 96, Train: Loss: 0.013303341343998909, acc: 99.609375\n",
      "Epoch: 96, Val: Loss: 1.0035549402236938, acc: 84.61538553237915\n",
      "Epoch: 97, Train: Loss: 0.012606699718162417, acc: 99.609375\n",
      "Epoch: 97, Val: Loss: 1.0104553699493408, acc: 84.61538553237915\n",
      "Epoch: 98, Train: Loss: 0.011809888994321227, acc: 99.609375\n",
      "Epoch: 98, Val: Loss: 1.0181281566619873, acc: 84.61538553237915\n",
      "Epoch: 99, Train: Loss: 0.01088612712919712, acc: 99.609375\n",
      "Epoch: 99, Val: Loss: 1.0269384384155273, acc: 84.61538553237915\n",
      "Epoch: 100, Train: Loss: 0.009801088366657495, acc: 99.609375\n",
      "Epoch: 100, Val: Loss: 1.037397861480713, acc: 84.61538553237915\n",
      "Epoch: 101, Train: Loss: 0.008516227826476097, acc: 99.609375\n",
      "Epoch: 101, Val: Loss: 1.0502347946166992, acc: 84.61538553237915\n",
      "Epoch: 102, Train: Loss: 0.00700529501773417, acc: 99.609375\n",
      "Epoch: 102, Val: Loss: 1.066501259803772, acc: 84.61538553237915\n",
      "Epoch: 103, Train: Loss: 0.005328719271346927, acc: 100.0\n",
      "Epoch: 103, Val: Loss: 1.0875078439712524, acc: 84.61538553237915\n",
      "Epoch: 104, Train: Loss: 0.0037753325887024403, acc: 100.0\n",
      "Epoch: 104, Val: Loss: 1.1137793064117432, acc: 84.61538553237915\n",
      "Epoch: 105, Train: Loss: 0.002616203506477177, acc: 100.0\n",
      "Epoch: 105, Val: Loss: 1.1433730125427246, acc: 84.61538553237915\n",
      "Epoch: 106, Train: Loss: 0.001756710815243423, acc: 100.0\n",
      "Epoch: 106, Val: Loss: 1.1732622385025024, acc: 84.61538553237915\n",
      "Epoch: 107, Train: Loss: 0.0011649029329419136, acc: 100.0\n",
      "Epoch: 107, Val: Loss: 1.2011960744857788, acc: 84.61538553237915\n",
      "Epoch: 108, Train: Loss: 0.0007970205042511225, acc: 100.0\n",
      "Epoch: 108, Val: Loss: 1.2260810136795044, acc: 84.61538553237915\n",
      "Epoch: 109, Train: Loss: 0.0005769128329120576, acc: 100.0\n",
      "Epoch: 109, Val: Loss: 1.2476654052734375, acc: 84.61538553237915\n",
      "Epoch: 110, Train: Loss: 0.0004420759796630591, acc: 100.0\n",
      "Epoch: 110, Val: Loss: 1.2661385536193848, acc: 84.61538553237915\n",
      "Epoch: 111, Train: Loss: 0.0003558922035153955, acc: 100.0\n",
      "Epoch: 111, Val: Loss: 1.281857967376709, acc: 84.61538553237915\n",
      "Epoch: 112, Train: Loss: 0.0002986141334986314, acc: 100.0\n",
      "Epoch: 112, Val: Loss: 1.2952126264572144, acc: 84.61538553237915\n",
      "Epoch: 113, Train: Loss: 0.000259117572568357, acc: 100.0\n",
      "Epoch: 113, Val: Loss: 1.3065661191940308, acc: 84.61538553237915\n",
      "Epoch: 114, Train: Loss: 0.0002309011688339524, acc: 100.0\n",
      "Epoch: 114, Val: Loss: 1.3162405490875244, acc: 84.61538553237915\n",
      "Epoch: 115, Train: Loss: 0.00021008994372095913, acc: 100.0\n",
      "Epoch: 115, Val: Loss: 1.3245131969451904, acc: 84.61538553237915\n",
      "Epoch: 116, Train: Loss: 0.0001943097886396572, acc: 100.0\n",
      "Epoch: 116, Val: Loss: 1.3316187858581543, acc: 84.61538553237915\n",
      "Epoch: 117, Train: Loss: 0.0001820438337745145, acc: 100.0\n",
      "Epoch: 117, Val: Loss: 1.3377530574798584, acc: 84.61538553237915\n",
      "Epoch: 118, Train: Loss: 0.00017231475067092106, acc: 100.0\n",
      "Epoch: 118, Val: Loss: 1.343078851699829, acc: 84.61538553237915\n",
      "Epoch: 119, Train: Loss: 0.00016445085930172354, acc: 100.0\n",
      "Epoch: 119, Val: Loss: 1.347731351852417, acc: 84.61538553237915\n",
      "Epoch: 120, Train: Loss: 0.00015800417895661667, acc: 100.0\n",
      "Epoch: 120, Val: Loss: 1.3518221378326416, acc: 84.61538553237915\n",
      "Epoch: 121, Train: Loss: 0.00015262942179106176, acc: 100.0\n",
      "Epoch: 121, Val: Loss: 1.355445146560669, acc: 84.61538553237915\n",
      "Epoch: 122, Train: Loss: 0.0001480936844018288, acc: 100.0\n",
      "Epoch: 122, Val: Loss: 1.3586764335632324, acc: 84.61538553237915\n",
      "Epoch: 123, Train: Loss: 0.00014421413652598858, acc: 100.0\n",
      "Epoch: 123, Val: Loss: 1.3615809679031372, acc: 84.61538553237915\n",
      "Epoch: 124, Train: Loss: 0.0001408650932717137, acc: 100.0\n",
      "Epoch: 124, Val: Loss: 1.3642115592956543, acc: 84.61538553237915\n",
      "Epoch: 125, Train: Loss: 0.0001379279710818082, acc: 100.0\n",
      "Epoch: 125, Val: Loss: 1.3666127920150757, acc: 84.61538553237915\n",
      "Epoch: 126, Train: Loss: 0.00013532750017475337, acc: 100.0\n",
      "Epoch: 126, Val: Loss: 1.3688209056854248, acc: 84.61538553237915\n",
      "Epoch: 127, Train: Loss: 0.00013300871796673164, acc: 100.0\n",
      "Epoch: 127, Val: Loss: 1.3708667755126953, acc: 84.61538553237915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Train: Loss: 0.00013091931759845465, acc: 100.0\n",
      "Epoch: 128, Val: Loss: 1.372775912284851, acc: 84.61538553237915\n",
      "Epoch: 129, Train: Loss: 0.00012901234003948048, acc: 100.0\n",
      "Epoch: 129, Val: Loss: 1.3745691776275635, acc: 84.61538553237915\n",
      "Epoch: 130, Train: Loss: 0.0001272676672670059, acc: 100.0\n",
      "Epoch: 130, Val: Loss: 1.3762648105621338, acc: 84.61538553237915\n",
      "Epoch: 131, Train: Loss: 0.00012564952703542076, acc: 100.0\n",
      "Epoch: 131, Val: Loss: 1.3778767585754395, acc: 84.61538553237915\n",
      "Epoch: 132, Train: Loss: 0.00012414660886861384, acc: 100.0\n",
      "Epoch: 132, Val: Loss: 1.3794171810150146, acc: 84.61538553237915\n",
      "Epoch: 133, Train: Loss: 0.00012274005712242797, acc: 100.0\n",
      "Epoch: 133, Val: Loss: 1.3808964490890503, acc: 84.61538553237915\n",
      "Epoch: 134, Train: Loss: 0.000121417277114233, acc: 100.0\n",
      "Epoch: 134, Val: Loss: 1.382323145866394, acc: 84.61538553237915\n",
      "Epoch: 135, Train: Loss: 0.00012015410538879223, acc: 100.0\n",
      "Epoch: 135, Val: Loss: 1.3837043046951294, acc: 84.61538553237915\n",
      "Epoch: 136, Train: Loss: 0.00011895601346623152, acc: 100.0\n",
      "Epoch: 136, Val: Loss: 1.3850460052490234, acc: 84.61538553237915\n",
      "Epoch: 137, Train: Loss: 0.00011781536159105599, acc: 100.0\n",
      "Epoch: 137, Val: Loss: 1.3863524198532104, acc: 84.61538553237915\n",
      "Epoch: 138, Train: Loss: 0.00011672150139929727, acc: 100.0\n",
      "Epoch: 138, Val: Loss: 1.387628436088562, acc: 84.61538553237915\n",
      "Epoch: 139, Train: Loss: 0.00011566107787075453, acc: 100.0\n",
      "Epoch: 139, Val: Loss: 1.3888771533966064, acc: 84.61538553237915\n",
      "Epoch: 140, Train: Loss: 0.00011464636554592289, acc: 100.0\n",
      "Epoch: 140, Val: Loss: 1.3901013135910034, acc: 84.61538553237915\n",
      "Epoch: 141, Train: Loss: 0.00011366432227077894, acc: 100.0\n",
      "Epoch: 141, Val: Loss: 1.3913040161132812, acc: 84.61538553237915\n",
      "Epoch: 142, Train: Loss: 0.00011270954928477295, acc: 100.0\n",
      "Epoch: 142, Val: Loss: 1.3924864530563354, acc: 84.61538553237915\n",
      "Epoch: 143, Train: Loss: 0.00011178975910297595, acc: 100.0\n",
      "Epoch: 143, Val: Loss: 1.393650770187378, acc: 84.61538553237915\n",
      "Epoch: 144, Train: Loss: 0.000110888562630862, acc: 100.0\n",
      "Epoch: 144, Val: Loss: 1.3947985172271729, acc: 84.61538553237915\n",
      "Epoch: 145, Train: Loss: 0.00011000674203387462, acc: 100.0\n",
      "Epoch: 145, Val: Loss: 1.3959307670593262, acc: 84.61538553237915\n",
      "Epoch: 146, Train: Loss: 0.00010915820530499332, acc: 100.0\n",
      "Epoch: 146, Val: Loss: 1.3970484733581543, acc: 84.61538553237915\n",
      "Epoch: 147, Train: Loss: 0.00010832360567292199, acc: 100.0\n",
      "Epoch: 147, Val: Loss: 1.3981531858444214, acc: 84.61538553237915\n",
      "Epoch: 148, Train: Loss: 0.00010750775982160121, acc: 100.0\n",
      "Epoch: 148, Val: Loss: 1.3992445468902588, acc: 84.61538553237915\n",
      "Epoch: 149, Train: Loss: 0.0001067135963239707, acc: 100.0\n",
      "Epoch: 149, Val: Loss: 1.4003243446350098, acc: 84.61538553237915\n",
      "Epoch: 150, Train: Loss: 0.00010594172636047006, acc: 100.0\n",
      "Epoch: 150, Val: Loss: 1.4013924598693848, acc: 84.61538553237915\n",
      "Epoch: 151, Train: Loss: 0.00010517605551285669, acc: 100.0\n",
      "Epoch: 151, Val: Loss: 1.4024498462677002, acc: 84.61538553237915\n",
      "Epoch: 152, Train: Loss: 0.00010443286373629235, acc: 100.0\n",
      "Epoch: 152, Val: Loss: 1.4034966230392456, acc: 84.61538553237915\n",
      "Epoch: 153, Train: Loss: 0.00010370653035352007, acc: 100.0\n",
      "Epoch: 153, Val: Loss: 1.4045332670211792, acc: 84.61538553237915\n",
      "Epoch: 154, Train: Loss: 0.00010298796041752212, acc: 100.0\n",
      "Epoch: 154, Val: Loss: 1.4055602550506592, acc: 84.61538553237915\n",
      "Epoch: 155, Train: Loss: 0.00010228872633888386, acc: 100.0\n",
      "Epoch: 155, Val: Loss: 1.406577467918396, acc: 84.61538553237915\n",
      "Epoch: 156, Train: Loss: 0.00010159911835216917, acc: 100.0\n",
      "Epoch: 156, Val: Loss: 1.4075859785079956, acc: 84.61538553237915\n",
      "Epoch: 157, Train: Loss: 0.00010092932643601671, acc: 100.0\n",
      "Epoch: 157, Val: Loss: 1.4085854291915894, acc: 84.61538553237915\n",
      "Epoch: 158, Train: Loss: 0.00010026031668530777, acc: 100.0\n",
      "Epoch: 158, Val: Loss: 1.4095762968063354, acc: 84.61538553237915\n",
      "Epoch: 159, Train: Loss: 9.961562318494543e-05, acc: 100.0\n",
      "Epoch: 159, Val: Loss: 1.4105585813522339, acc: 84.61538553237915\n",
      "Epoch: 160, Train: Loss: 9.897681229631416e-05, acc: 100.0\n",
      "Epoch: 160, Val: Loss: 1.4115327596664429, acc: 84.61538553237915\n",
      "Epoch: 161, Train: Loss: 9.834683078224771e-05, acc: 100.0\n",
      "Epoch: 161, Val: Loss: 1.4124987125396729, acc: 84.61538553237915\n",
      "Epoch: 162, Train: Loss: 9.773219062481076e-05, acc: 100.0\n",
      "Epoch: 162, Val: Loss: 1.4134567975997925, acc: 84.61538553237915\n",
      "Epoch: 163, Train: Loss: 9.712203609524295e-05, acc: 100.0\n",
      "Epoch: 163, Val: Loss: 1.4144072532653809, acc: 84.61538553237915\n",
      "Epoch: 164, Train: Loss: 9.653094093664549e-05, acc: 100.0\n",
      "Epoch: 164, Val: Loss: 1.415350079536438, acc: 84.61538553237915\n",
      "Epoch: 165, Train: Loss: 9.594604125595652e-05, acc: 100.0\n",
      "Epoch: 165, Val: Loss: 1.4162856340408325, acc: 84.61538553237915\n",
      "Epoch: 166, Train: Loss: 9.537058940622956e-05, acc: 100.0\n",
      "Epoch: 166, Val: Loss: 1.4172136783599854, acc: 84.61538553237915\n",
      "Epoch: 167, Train: Loss: 9.480705193709582e-05, acc: 100.0\n",
      "Epoch: 167, Val: Loss: 1.4181348085403442, acc: 84.61538553237915\n",
      "Epoch: 168, Train: Loss: 9.424958261661232e-05, acc: 100.0\n",
      "Epoch: 168, Val: Loss: 1.419048547744751, acc: 84.61538553237915\n",
      "Epoch: 169, Train: Loss: 9.370587576995604e-05, acc: 100.0\n",
      "Epoch: 169, Val: Loss: 1.4199557304382324, acc: 84.61538553237915\n",
      "Epoch: 170, Train: Loss: 9.316497016698122e-05, acc: 100.0\n",
      "Epoch: 170, Val: Loss: 1.4208558797836304, acc: 84.61538553237915\n",
      "Epoch: 171, Train: Loss: 9.263521133107133e-05, acc: 100.0\n",
      "Epoch: 171, Val: Loss: 1.4217497110366821, acc: 84.61538553237915\n",
      "Epoch: 172, Train: Loss: 9.21178470889572e-05, acc: 100.0\n",
      "Epoch: 172, Val: Loss: 1.42263662815094, acc: 84.61538553237915\n",
      "Epoch: 173, Train: Loss: 9.160374611383304e-05, acc: 100.0\n",
      "Epoch: 173, Val: Loss: 1.4235167503356934, acc: 84.61538553237915\n",
      "Epoch: 174, Train: Loss: 9.10942762857303e-05, acc: 100.0\n",
      "Epoch: 174, Val: Loss: 1.424391269683838, acc: 84.61538553237915\n",
      "Epoch: 175, Train: Loss: 9.059410513145849e-05, acc: 100.0\n",
      "Epoch: 175, Val: Loss: 1.4252591133117676, acc: 84.61538553237915\n",
      "Epoch: 176, Train: Loss: 9.010570647660643e-05, acc: 100.0\n",
      "Epoch: 176, Val: Loss: 1.4261207580566406, acc: 84.61538553237915\n",
      "Epoch: 177, Train: Loss: 8.962335414253175e-05, acc: 100.0\n",
      "Epoch: 177, Val: Loss: 1.4269765615463257, acc: 84.61538553237915\n",
      "Epoch: 178, Train: Loss: 8.91506097104866e-05, acc: 100.0\n",
      "Epoch: 178, Val: Loss: 1.4278264045715332, acc: 84.61538553237915\n",
      "Epoch: 179, Train: Loss: 8.868498480296694e-05, acc: 100.0\n",
      "Epoch: 179, Val: Loss: 1.4286702871322632, acc: 84.61538553237915\n",
      "Epoch: 180, Train: Loss: 8.821889423415996e-05, acc: 100.0\n",
      "Epoch: 180, Val: Loss: 1.4295084476470947, acc: 84.61538553237915\n",
      "Epoch: 181, Train: Loss: 8.776659888098948e-05, acc: 100.0\n",
      "Epoch: 181, Val: Loss: 1.4303408861160278, acc: 84.61538553237915\n",
      "Epoch: 182, Train: Loss: 8.731693742447533e-05, acc: 100.0\n",
      "Epoch: 182, Val: Loss: 1.4311676025390625, acc: 84.61538553237915\n",
      "Epoch: 183, Train: Loss: 8.687300214660354e-05, acc: 100.0\n",
      "Epoch: 183, Val: Loss: 1.4319889545440674, acc: 84.61538553237915\n",
      "Epoch: 184, Train: Loss: 8.644332046969794e-05, acc: 100.0\n",
      "Epoch: 184, Val: Loss: 1.4328047037124634, acc: 84.61538553237915\n",
      "Epoch: 185, Train: Loss: 8.601471927249804e-05, acc: 100.0\n",
      "Epoch: 185, Val: Loss: 1.4336153268814087, acc: 84.61538553237915\n",
      "Epoch: 186, Train: Loss: 8.559308480471373e-05, acc: 100.0\n",
      "Epoch: 186, Val: Loss: 1.4344204664230347, acc: 84.61538553237915\n",
      "Epoch: 187, Train: Loss: 8.517611786373891e-05, acc: 100.0\n",
      "Epoch: 187, Val: Loss: 1.4352202415466309, acc: 84.61538553237915\n",
      "Epoch: 188, Train: Loss: 8.476564471493475e-05, acc: 100.0\n",
      "Epoch: 188, Val: Loss: 1.436015009880066, acc: 84.61538553237915\n",
      "Epoch: 189, Train: Loss: 8.43562556838151e-05, acc: 100.0\n",
      "Epoch: 189, Val: Loss: 1.4368048906326294, acc: 84.61538553237915\n",
      "Epoch: 190, Train: Loss: 8.395956683671102e-05, acc: 100.0\n",
      "Epoch: 190, Val: Loss: 1.4375895261764526, acc: 84.61538553237915\n",
      "Epoch: 191, Train: Loss: 8.356567195733078e-05, acc: 100.0\n",
      "Epoch: 191, Val: Loss: 1.4383695125579834, acc: 84.61538553237915\n",
      "Epoch: 192, Train: Loss: 8.317689207615331e-05, acc: 100.0\n",
      "Epoch: 192, Val: Loss: 1.439144253730774, acc: 84.61538553237915\n",
      "Epoch: 193, Train: Loss: 8.279105895780958e-05, acc: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193, Val: Loss: 1.4399142265319824, acc: 84.61538553237915\n",
      "Epoch: 194, Train: Loss: 8.241420800914057e-05, acc: 100.0\n",
      "Epoch: 194, Val: Loss: 1.4406797885894775, acc: 84.61538553237915\n",
      "Epoch: 195, Train: Loss: 8.204028927139007e-05, acc: 100.0\n",
      "Epoch: 195, Val: Loss: 1.4414401054382324, acc: 84.61538553237915\n",
      "Epoch: 196, Train: Loss: 8.167506530298851e-05, acc: 100.0\n",
      "Epoch: 196, Val: Loss: 1.4421964883804321, acc: 84.61538553237915\n",
      "Epoch: 197, Train: Loss: 8.130719652399421e-05, acc: 100.0\n",
      "Epoch: 197, Val: Loss: 1.4429479837417603, acc: 84.61538553237915\n",
      "Epoch: 198, Train: Loss: 8.094769873423502e-05, acc: 100.0\n",
      "Epoch: 198, Val: Loss: 1.4436951875686646, acc: 84.61538553237915\n",
      "Epoch: 199, Train: Loss: 8.059067840804346e-05, acc: 100.0\n",
      "Epoch: 199, Val: Loss: 1.4444377422332764, acc: 84.61538553237915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_self_attention_layer_call_fn, multi_head_self_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn while saving (showing 5 of 216). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: adv_KWS_transformer2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: adv_KWS_transformer2/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_self_attention_layer_call_fn, multi_head_self_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn while saving (showing 5 of 216). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: adv_KWS_transformer2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: adv_KWS_transformer2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack started for testing\n",
      "adv_tmp/test\n",
      "adv_tmp/test/on\n",
      "7.06111478805542\n",
      "0 tf.Tensor(\n",
      "[1.01253185e+01 1.04279861e+01 1.03641911e+01 1.00855989e+01\n",
      " 1.76321890e-03 3.43502179e-04 9.52356052e+00 7.60266208e-04\n",
      " 1.04085388e+01 3.75502204e-05 1.27865549e-03 3.15899633e-05\n",
      " 1.14065898e-03 5.59170151e+00 1.43419945e+00 1.03935699e+01\n",
      " 8.46915817e+00 6.42517407e-05 1.02032938e+01 9.97730541e+00\n",
      " 1.03925028e+01 3.67157882e-05 1.05544977e+01 1.04135628e+01\n",
      " 7.43510628e+00 1.03998871e+01 3.20100505e-03 1.02823887e+01\n",
      " 1.18519145e-03 8.91645759e-05 1.01772366e+01 9.80709648e+00\n",
      " 1.02306805e+01 9.95536709e+00 1.01687622e+01 2.87610659e-04\n",
      " 1.74268789e-04 9.66082573e+00 1.00411377e+01 1.04181690e+01\n",
      " 1.00976343e+01 9.68049335e+00 3.12323464e-05 7.77378178e+00\n",
      " 4.59446252e-04 4.02012112e-04 3.63283907e-04 1.05511637e+01\n",
      " 1.03358612e+01 6.71605635e+00 1.04669189e+01 1.04872103e+01\n",
      " 5.67751878e-04 1.32472941e-03 1.04364614e+01 1.50986171e+00\n",
      " 1.02705650e+01 1.04636726e+01 1.96782500e-02 3.54227261e-04\n",
      " 9.71084053e-04 1.02930632e+01 9.99698067e+00 9.60003281e+00\n",
      " 6.03017164e-04 1.03253212e+01 2.40773777e-04 1.03614902e+01\n",
      " 9.77652836e+00 3.34922021e-04 8.73293591e+00 1.02657652e+01\n",
      " 1.02901287e+01 1.06686624e-04 2.68217300e-05 1.03516846e+01\n",
      " 9.41548438e-04 1.00880194e+01 3.93313298e-04 1.04810057e+01\n",
      " 1.12672721e-03 1.01266623e+01 1.13123220e-04 7.50442028e+00\n",
      " 1.02562380e+01 1.81641022e-03 1.03549299e+01 1.02352829e+01\n",
      " 1.21233857e-03 1.54840876e-04 3.27891001e-04 1.04003296e+01\n",
      " 1.04859343e+01 4.06941175e-02 1.04993420e+01 1.01932211e+01\n",
      " 9.06410885e+00 8.09576416e+00 1.02629261e+01 9.87371063e+00\n",
      " 1.04388933e+01 8.10887146e+00 1.10858491e-04 3.42124804e-05\n",
      " 1.14829335e-02 1.03943958e+01 5.06153738e-04 3.54045333e-05\n",
      " 3.17403959e-04 1.00929289e+01 1.01950769e+01 9.98214149e+00\n",
      " 1.03070240e+01 9.86357021e+00 9.77077484e+00 9.99324131e+00\n",
      " 1.03428783e+01 1.16018832e+00 1.03129120e+01 1.02941694e+01\n",
      " 4.15953895e-04 1.77367692e-04 3.00402899e-05 1.01143751e+01\n",
      " 1.04596043e+01 7.68723607e-04 1.05009079e+01 1.04984465e+01], shape=(128,), dtype=float32) [1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
      " 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1]\n",
      "It's way over 0.0065419235229492185\n",
      "Worked i=4 loss=0.001763 bound=11.775463\n",
      "First hit for audio 4 at iteration 0\n",
      "It's way over 0.003772559404373169\n",
      "Worked i=5 loss=0.000344 bound=6.790607\n",
      "First hit for audio 5 at iteration 0\n",
      "It's way over 0.006001583576202393\n",
      "Worked i=7 loss=0.000760 bound=10.802851\n",
      "First hit for audio 7 at iteration 0\n",
      "It's way over 0.0002811740040779114\n",
      "Worked i=9 loss=0.000038 bound=0.506113\n",
      "First hit for audio 9 at iteration 0\n",
      "It's way over 0.004864694118499756\n",
      "Worked i=10 loss=0.001279 bound=8.756450\n",
      "First hit for audio 10 at iteration 0\n",
      "It's way over 0.0016159476041793823\n",
      "Worked i=11 loss=0.000032 bound=2.908706\n",
      "First hit for audio 11 at iteration 0\n",
      "It's way over 0.003735839128494263\n",
      "Worked i=12 loss=0.001141 bound=6.724510\n",
      "First hit for audio 12 at iteration 0\n",
      "It's way over 0.0010890965461730958\n",
      "Worked i=17 loss=0.000064 bound=1.960374\n",
      "First hit for audio 17 at iteration 0\n",
      "It's way over 0.00024671266973018646\n",
      "Worked i=21 loss=0.000037 bound=0.444083\n",
      "First hit for audio 21 at iteration 0\n",
      "It's way over 0.0067199721336364746\n",
      "Worked i=26 loss=0.003201 bound=12.095949\n",
      "First hit for audio 26 at iteration 0\n",
      "It's way over 0.006093050003051758\n",
      "Worked i=28 loss=0.001185 bound=10.967489\n",
      "First hit for audio 28 at iteration 0\n",
      "It's way over 0.003758555173873901\n",
      "Worked i=29 loss=0.000089 bound=6.765399\n",
      "First hit for audio 29 at iteration 0\n",
      "It's way over 0.001711317539215088\n",
      "Worked i=35 loss=0.000288 bound=3.080372\n",
      "First hit for audio 35 at iteration 0\n",
      "It's way over 0.0013221019506454467\n",
      "Worked i=36 loss=0.000174 bound=2.379783\n",
      "First hit for audio 36 at iteration 0\n",
      "It's way over 0.00059669029712677\n",
      "Worked i=42 loss=0.000031 bound=1.074043\n",
      "First hit for audio 42 at iteration 0\n",
      "It's way over 0.005769069194793701\n",
      "Worked i=44 loss=0.000459 bound=10.384325\n",
      "First hit for audio 44 at iteration 0\n",
      "It's way over 0.004428142547607422\n",
      "Worked i=45 loss=0.000402 bound=7.970657\n",
      "First hit for audio 45 at iteration 0\n",
      "It's way over 0.004248332500457763\n",
      "Worked i=46 loss=0.000363 bound=7.646999\n",
      "First hit for audio 46 at iteration 0\n",
      "It's way over 0.006412343025207519\n",
      "Worked i=52 loss=0.000568 bound=11.542218\n",
      "First hit for audio 52 at iteration 0\n",
      "It's way over 0.004333373546600342\n",
      "Worked i=53 loss=0.001325 bound=7.800073\n",
      "First hit for audio 53 at iteration 0\n",
      "It's way over 0.006748164176940918\n",
      "Worked i=58 loss=0.019678 bound=12.146695\n",
      "First hit for audio 58 at iteration 0\n",
      "It's way over 0.002531628131866455\n",
      "Worked i=59 loss=0.000354 bound=4.556931\n",
      "First hit for audio 59 at iteration 0\n",
      "It's way over 0.006049232006072998\n",
      "Worked i=60 loss=0.000971 bound=10.888618\n",
      "First hit for audio 60 at iteration 0\n",
      "It's way over 0.005118447780609131\n",
      "Worked i=64 loss=0.000603 bound=9.213206\n",
      "First hit for audio 64 at iteration 0\n",
      "It's way over 0.006721254348754883\n",
      "Worked i=66 loss=0.000241 bound=12.098258\n",
      "First hit for audio 66 at iteration 0\n",
      "It's way over 0.0036398537158966065\n",
      "Worked i=69 loss=0.000335 bound=6.551737\n",
      "First hit for audio 69 at iteration 0\n",
      "It's way over 0.004892529487609864\n",
      "Worked i=73 loss=0.000107 bound=8.806553\n",
      "First hit for audio 73 at iteration 0\n",
      "It's way over 0.00028855356574058533\n",
      "Worked i=74 loss=0.000027 bound=0.519396\n",
      "First hit for audio 74 at iteration 0\n",
      "It's way over 0.0064374098777771\n",
      "Worked i=76 loss=0.000942 bound=11.587337\n",
      "First hit for audio 76 at iteration 0\n",
      "It's way over 0.005457629203796386\n",
      "Worked i=78 loss=0.000393 bound=9.823732\n",
      "First hit for audio 78 at iteration 0\n",
      "It's way over 0.00646744966506958\n",
      "Worked i=80 loss=0.001127 bound=11.641409\n",
      "First hit for audio 80 at iteration 0\n",
      "It's way over 0.002571007251739502\n",
      "Worked i=82 loss=0.000113 bound=4.627813\n",
      "First hit for audio 82 at iteration 0\n",
      "It's way over 0.006651681900024414\n",
      "Worked i=85 loss=0.001816 bound=11.973027\n",
      "First hit for audio 85 at iteration 0\n",
      "It's way over 0.005887312412261963\n",
      "Worked i=88 loss=0.001212 bound=10.597162\n",
      "First hit for audio 88 at iteration 0\n",
      "It's way over 0.0031744506359100344\n",
      "Worked i=89 loss=0.000155 bound=5.714011\n",
      "First hit for audio 89 at iteration 0\n",
      "It's way over 0.006566936016082763\n",
      "Worked i=90 loss=0.000328 bound=11.820485\n",
      "First hit for audio 90 at iteration 0\n",
      "It's way over 0.006745135307312012\n",
      "Worked i=93 loss=0.040694 bound=12.141244\n",
      "First hit for audio 93 at iteration 0\n",
      "It's way over 0.005903859615325927\n",
      "Worked i=102 loss=0.000111 bound=10.626947\n",
      "First hit for audio 102 at iteration 0\n",
      "It's way over 7.94418603181839e-05\n",
      "Worked i=103 loss=0.000034 bound=0.142995\n",
      "First hit for audio 103 at iteration 0\n",
      "It's way over 0.006745563507080078\n",
      "Worked i=104 loss=0.011483 bound=12.142014\n",
      "First hit for audio 104 at iteration 0\n",
      "It's way over 0.0031001479625701904\n",
      "Worked i=106 loss=0.000506 bound=5.580266\n",
      "First hit for audio 106 at iteration 0\n",
      "It's way over 0.0001576032191514969\n",
      "Worked i=107 loss=0.000035 bound=0.283686\n",
      "First hit for audio 107 at iteration 0\n",
      "It's way over 0.005697832107543945\n",
      "Worked i=108 loss=0.000317 bound=10.256098\n",
      "First hit for audio 108 at iteration 0\n",
      "It's way over 0.005549457550048828\n",
      "Worked i=120 loss=0.000416 bound=9.989023\n",
      "First hit for audio 120 at iteration 0\n",
      "It's way over 0.0005194063186645507\n",
      "Worked i=121 loss=0.000177 bound=0.934931\n",
      "First hit for audio 121 at iteration 0\n",
      "It's way over 6.527730822563171e-05\n",
      "Worked i=122 loss=0.000030 bound=0.117499\n",
      "First hit for audio 122 at iteration 0\n",
      "It's way over 0.006263154983520508\n",
      "Worked i=125 loss=0.000769 bound=11.273680\n",
      "First hit for audio 125 at iteration 0\n",
      "It's way over 0.10159794616699219\n",
      "Worked i=0 loss=0.000193 bound=182.876297\n",
      "First hit for audio 0 at iteration 99\n",
      "It's way over 0.09996999359130859\n",
      "Worked i=1 loss=0.000199 bound=179.945969\n",
      "First hit for audio 1 at iteration 99\n",
      "It's way over 0.08321778106689454\n",
      "Worked i=2 loss=0.000184 bound=149.792023\n",
      "First hit for audio 2 at iteration 99\n",
      "It's way over 0.07392232513427735\n",
      "Worked i=3 loss=0.000155 bound=133.060181\n",
      "First hit for audio 3 at iteration 99\n",
      "It's way over 0.1086380844116211\n",
      "Worked i=6 loss=0.000431 bound=195.548553\n",
      "First hit for audio 6 at iteration 99\n",
      "It's way over 0.07701467895507813\n",
      "Worked i=8 loss=0.000169 bound=138.626419\n",
      "First hit for audio 8 at iteration 99\n",
      "It's way over 0.11268810272216796\n",
      "Worked i=13 loss=0.000323 bound=202.838577\n",
      "First hit for audio 13 at iteration 99\n",
      "It's way over 0.12011327362060546\n",
      "Worked i=14 loss=0.000042 bound=216.203903\n",
      "First hit for audio 14 at iteration 99\n",
      "It's way over 0.07410682678222656\n",
      "Worked i=15 loss=0.000028 bound=133.392288\n",
      "First hit for audio 15 at iteration 99\n",
      "It's way over 0.07172884368896484\n",
      "Worked i=16 loss=0.000251 bound=129.111923\n",
      "First hit for audio 16 at iteration 99\n",
      "It's way over 0.13471116638183595\n",
      "Worked i=18 loss=0.000084 bound=242.480087\n",
      "First hit for audio 18 at iteration 99\n",
      "It's way over 0.0796451416015625\n",
      "Worked i=19 loss=0.000180 bound=143.361252\n",
      "First hit for audio 19 at iteration 99\n",
      "It's way over 0.07062917327880859\n",
      "Worked i=20 loss=0.000039 bound=127.132507\n",
      "First hit for audio 20 at iteration 99\n",
      "It's way over 0.09751194763183593\n",
      "Worked i=22 loss=0.000064 bound=175.521515\n",
      "First hit for audio 22 at iteration 99\n",
      "It's way over 0.09938068389892578\n",
      "Worked i=23 loss=0.000105 bound=178.885239\n",
      "First hit for audio 23 at iteration 99\n",
      "It's way over 0.10268985748291015\n",
      "Worked i=24 loss=0.000274 bound=184.841736\n",
      "First hit for audio 24 at iteration 99\n",
      "It's way over 0.09873040771484375\n",
      "Worked i=25 loss=0.000181 bound=177.714737\n",
      "First hit for audio 25 at iteration 99\n",
      "It's way over 0.09178382110595704\n",
      "Worked i=27 loss=0.000170 bound=165.210876\n",
      "First hit for audio 27 at iteration 99\n",
      "It's way over 0.10109944915771485\n",
      "Worked i=30 loss=0.000343 bound=181.979004\n",
      "First hit for audio 30 at iteration 99\n",
      "It's way over 0.1166432876586914\n",
      "Worked i=31 loss=0.000476 bound=209.957916\n",
      "First hit for audio 31 at iteration 99\n",
      "It's way over 0.10604025268554687\n",
      "Worked i=32 loss=0.000031 bound=190.872467\n",
      "First hit for audio 32 at iteration 99\n",
      "It's way over 0.11338957214355469\n",
      "Worked i=33 loss=0.000172 bound=204.101242\n",
      "First hit for audio 33 at iteration 99\n",
      "It's way over 0.09948831939697265\n",
      "Worked i=34 loss=0.000280 bound=179.078964\n",
      "First hit for audio 34 at iteration 99\n",
      "It's way over 0.1683964080810547\n",
      "Worked i=37 loss=0.000353 bound=303.113556\n",
      "First hit for audio 37 at iteration 99\n",
      "It's way over 0.12283989715576171\n",
      "Worked i=38 loss=0.000241 bound=221.111816\n",
      "First hit for audio 38 at iteration 99\n",
      "It's way over 0.09987797546386719\n",
      "Worked i=39 loss=0.000138 bound=179.780365\n",
      "First hit for audio 39 at iteration 99\n",
      "It's way over 0.06926081848144532\n",
      "Worked i=40 loss=0.000124 bound=124.669479\n",
      "First hit for audio 40 at iteration 99\n",
      "It's way over 0.07608356475830078\n",
      "Worked i=41 loss=0.000201 bound=136.950424\n",
      "First hit for audio 41 at iteration 99\n",
      "It's way over 0.1285542449951172\n",
      "Worked i=43 loss=0.000335 bound=231.397629\n",
      "First hit for audio 43 at iteration 99\n",
      "It's way over 0.1234541244506836\n",
      "Worked i=47 loss=0.000150 bound=222.217422\n",
      "First hit for audio 47 at iteration 99\n",
      "It's way over 0.10571542358398438\n",
      "Worked i=48 loss=0.000244 bound=190.287766\n",
      "First hit for audio 48 at iteration 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's way over 0.20530612182617186\n",
      "Worked i=49 loss=0.000676 bound=369.551025\n",
      "First hit for audio 49 at iteration 99\n",
      "It's way over 0.09913823699951171\n",
      "Worked i=50 loss=0.000161 bound=178.448822\n",
      "First hit for audio 50 at iteration 99\n",
      "It's way over 0.12124479675292969\n",
      "Worked i=51 loss=0.000028 bound=218.240631\n",
      "First hit for audio 51 at iteration 99\n",
      "It's way over 0.10410883331298829\n",
      "Worked i=54 loss=0.000119 bound=187.395905\n",
      "First hit for audio 54 at iteration 99\n",
      "It's way over 0.19941059875488282\n",
      "Worked i=55 loss=0.000304 bound=358.939087\n",
      "First hit for audio 55 at iteration 99\n",
      "It's way over 0.10445011138916016\n",
      "Worked i=56 loss=0.000239 bound=188.010208\n",
      "First hit for audio 56 at iteration 99\n",
      "It's way over 0.09970072174072266\n",
      "Worked i=57 loss=0.000189 bound=179.461304\n",
      "First hit for audio 57 at iteration 99\n",
      "It's way over 0.06921963500976562\n",
      "Worked i=61 loss=0.000163 bound=124.595345\n",
      "First hit for audio 61 at iteration 99\n",
      "It's way over 0.10701482391357423\n",
      "Worked i=62 loss=0.000180 bound=192.626678\n",
      "First hit for audio 62 at iteration 99\n",
      "It's way over 0.1419546661376953\n",
      "Worked i=63 loss=0.000230 bound=255.518372\n",
      "First hit for audio 63 at iteration 99\n",
      "It's way over 0.09224222564697265\n",
      "Worked i=65 loss=0.000027 bound=166.036011\n",
      "First hit for audio 65 at iteration 99\n",
      "It's way over 0.10172694396972656\n",
      "Worked i=67 loss=0.000494 bound=183.108490\n",
      "First hit for audio 67 at iteration 99\n",
      "It's way over 0.07929586029052735\n",
      "Worked i=68 loss=0.000184 bound=142.732544\n",
      "First hit for audio 68 at iteration 99\n",
      "It's way over 0.11055847930908203\n",
      "Worked i=70 loss=0.000357 bound=199.005264\n",
      "First hit for audio 70 at iteration 99\n",
      "It's way over 0.08570145416259765\n",
      "Worked i=71 loss=0.000131 bound=154.262619\n",
      "First hit for audio 71 at iteration 99\n",
      "It's way over 0.11836083221435546\n",
      "Worked i=72 loss=0.000029 bound=213.049500\n",
      "First hit for audio 72 at iteration 99\n",
      "It's way over 0.0738463134765625\n",
      "Worked i=75 loss=0.000022 bound=132.923370\n",
      "First hit for audio 75 at iteration 99\n",
      "It's way over 0.109093994140625\n",
      "Worked i=77 loss=0.000193 bound=196.369186\n",
      "First hit for audio 77 at iteration 99\n",
      "It's way over 0.15766763305664064\n",
      "Worked i=79 loss=0.000108 bound=283.801727\n",
      "First hit for audio 79 at iteration 99\n",
      "It's way over 0.08058336639404297\n",
      "Worked i=81 loss=0.000034 bound=145.050049\n",
      "First hit for audio 81 at iteration 99\n",
      "It's way over 0.12736377716064454\n",
      "Worked i=83 loss=0.000360 bound=229.254776\n",
      "First hit for audio 83 at iteration 99\n",
      "It's way over 0.09405931854248047\n",
      "Worked i=84 loss=0.000037 bound=169.306763\n",
      "First hit for audio 84 at iteration 99\n",
      "It's way over 0.10079220581054688\n",
      "Worked i=86 loss=0.000271 bound=181.425980\n",
      "First hit for audio 86 at iteration 99\n",
      "It's way over 0.07839569854736328\n",
      "Worked i=87 loss=0.000138 bound=141.112274\n",
      "First hit for audio 87 at iteration 99\n",
      "It's way over 0.14097189331054688\n",
      "Worked i=91 loss=0.000093 bound=253.749435\n",
      "First hit for audio 91 at iteration 99\n",
      "It's way over 0.12111492919921875\n",
      "Worked i=92 loss=0.000025 bound=218.006882\n",
      "First hit for audio 92 at iteration 99\n",
      "It's way over 0.11819831848144531\n",
      "Worked i=94 loss=0.000023 bound=212.756973\n",
      "First hit for audio 94 at iteration 99\n",
      "It's way over 0.08346846008300782\n",
      "Worked i=95 loss=0.000230 bound=150.243225\n",
      "First hit for audio 95 at iteration 99\n",
      "It's way over 0.08883588409423829\n",
      "Worked i=96 loss=0.000039 bound=159.904602\n",
      "First hit for audio 96 at iteration 99\n",
      "It's way over 0.08940224456787109\n",
      "Worked i=97 loss=0.000479 bound=160.924026\n",
      "First hit for audio 97 at iteration 99\n",
      "It's way over 0.09545336151123048\n",
      "Worked i=98 loss=0.000204 bound=171.816055\n",
      "First hit for audio 98 at iteration 99\n",
      "It's way over 0.07822608947753906\n",
      "Worked i=99 loss=0.000168 bound=140.806961\n",
      "First hit for audio 99 at iteration 99\n",
      "It's way over 0.12338513946533203\n",
      "Worked i=100 loss=0.000140 bound=222.093262\n",
      "First hit for audio 100 at iteration 99\n",
      "It's way over 0.10173150634765625\n",
      "Worked i=101 loss=0.000206 bound=183.116714\n",
      "First hit for audio 101 at iteration 99\n",
      "It's way over 0.10811018371582032\n",
      "Worked i=105 loss=0.000025 bound=194.598328\n",
      "First hit for audio 105 at iteration 99\n",
      "It's way over 0.09993473815917969\n",
      "Worked i=109 loss=0.000165 bound=179.882538\n",
      "First hit for audio 109 at iteration 99\n",
      "It's way over 0.08124227142333984\n",
      "Worked i=110 loss=0.000158 bound=146.236099\n",
      "First hit for audio 110 at iteration 99\n",
      "It's way over 0.16689280700683592\n",
      "Worked i=111 loss=0.000222 bound=300.407043\n",
      "First hit for audio 111 at iteration 99\n",
      "It's way over 0.14347181701660155\n",
      "Worked i=112 loss=0.000130 bound=258.249268\n",
      "First hit for audio 112 at iteration 99\n",
      "It's way over 0.07010697174072265\n",
      "Worked i=113 loss=0.000187 bound=126.192543\n",
      "First hit for audio 113 at iteration 99\n",
      "It's way over 0.11196799468994141\n",
      "Worked i=114 loss=0.000031 bound=201.542389\n",
      "First hit for audio 114 at iteration 99\n",
      "It's way over 0.1134715576171875\n",
      "Worked i=115 loss=0.000194 bound=204.248810\n",
      "First hit for audio 115 at iteration 99\n",
      "It's way over 0.09982269287109374\n",
      "Worked i=116 loss=0.000042 bound=179.680847\n",
      "First hit for audio 116 at iteration 99\n",
      "It's way over 0.11055374145507812\n",
      "Worked i=117 loss=0.000471 bound=198.996735\n",
      "First hit for audio 117 at iteration 99\n",
      "It's way over 0.06836763000488282\n",
      "Worked i=118 loss=0.000022 bound=123.061729\n",
      "First hit for audio 118 at iteration 99\n",
      "It's way over 0.10064004516601563\n",
      "Worked i=119 loss=0.000294 bound=181.152069\n",
      "First hit for audio 119 at iteration 99\n",
      "It's way over 0.11112387084960937\n",
      "Worked i=123 loss=0.000208 bound=200.022964\n",
      "First hit for audio 123 at iteration 99\n",
      "It's way over 0.06905673980712891\n",
      "Worked i=124 loss=0.000021 bound=124.302132\n",
      "First hit for audio 124 at iteration 99\n",
      "It's way over 0.12199597930908203\n",
      "Worked i=126 loss=0.000021 bound=219.592758\n",
      "First hit for audio 126 at iteration 99\n",
      "It's way over 0.09862619018554687\n",
      "Worked i=127 loss=0.000025 bound=177.527145\n",
      "First hit for audio 127 at iteration 99\n",
      "adv_tmp/test\n",
      "adv_tmp/test/off\n",
      "6.459836959838867\n",
      "0 tf.Tensor(\n",
      "[2.37706494e+00 6.23445158e-05 9.40010738e+00 2.81329958e-05\n",
      " 3.43316860e-05 1.02706003e+01 1.04608011e+01 5.71099758e+00\n",
      " 8.77898312e+00 3.15899633e-05 2.65324663e-04 3.34972501e-05\n",
      " 9.47668959e-05 3.57621466e-05 8.49926146e-05 5.15574646e+00\n",
      " 5.60189772e+00 3.34972501e-05 8.00016212e+00 8.63510227e+00\n",
      " 3.27820162e-05 2.89674372e-05 4.97090368e-05 2.39607798e-05\n",
      " 9.93073082e+00 7.89902878e+00 3.06363181e-05 1.04440212e+01\n",
      " 1.01144428e+01 3.67157882e-05 1.20155746e-04 3.18283746e-05\n",
      " 4.25568105e-05 8.20452404e+00 3.61197635e-05 7.02118050e-05\n",
      " 3.13515520e-05 4.45832811e-05 3.12323464e-05 3.11131407e-05\n",
      " 9.81388855e+00 9.92463779e+00 3.01594955e-05 2.84906146e-05\n",
      " 6.73509785e-05 4.38106585e+00 2.64641112e-05 9.26014709e+00\n",
      " 2.82522033e-05 5.02128649e+00 8.90410233e+00 7.67684841e+00\n",
      " 7.82631683e+00 1.01078882e+01 5.17354929e-05 3.30204275e-05\n",
      " 2.70601431e-05 5.55499864e-05 9.89923096e+00 3.26628106e-05\n",
      " 7.44690514e+00 4.24376049e-05 8.27935886e+00 2.77753788e-05\n",
      " 4.14839706e-05 9.54225540e+00 4.58945251e-05 3.88594437e+00\n",
      " 1.44232836e-04 2.75369675e-05 3.70734015e-05 6.40133367e-05\n",
      " 6.56039640e-02 9.86683273e+00 1.06422777e+01 6.17797207e-03\n",
      " 5.84108457e-05 1.24804341e-04 8.89333344e+00 8.77643466e-01\n",
      " 3.89806773e-05 7.86762476e+00 2.67025243e-05 3.26628106e-05\n",
      " 3.49277107e-05 3.50469163e-05 3.18283746e-05 2.81329958e-05\n",
      " 3.82654507e-05 5.68438768e+00 4.38965464e+00 3.62389692e-05\n",
      " 1.00042067e+01 1.13480804e-04 9.36143684e+00 5.56691884e-05\n",
      " 7.14462090e+00 7.53696537e+00 4.02919286e-05 1.00417385e+01\n",
      " 6.19952679e+00 7.51260662e+00 3.19475803e-05 3.03979068e-05\n",
      " 6.93773982e-05 7.78174543e+00 8.44879627e+00 2.87290259e-05\n",
      " 5.99604755e-05 4.25568105e-05 3.26628106e-05 8.45250797e+00\n",
      " 8.97661400e+00 2.86098202e-05 1.04851732e+01 6.06756876e-05\n",
      " 7.12846158e-05 6.29111290e+00 9.89184093e+00 4.32720371e-05\n",
      " 3.20667859e-05 6.78277866e-05 2.65833187e-05 5.29037476e+00\n",
      " 4.95898348e-05 8.59635162e+00 2.96826729e-05 2.96826729e-05], shape=(128,), dtype=float32) [0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0\n",
      " 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1\n",
      " 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1]\n",
      "It's way over 0.0037091660499572756\n",
      "Worked i=1 loss=0.000062 bound=6.676499\n",
      "First hit for audio 1 at iteration 0\n",
      "It's way over 0.00020283931493759156\n",
      "Worked i=3 loss=0.000028 bound=0.365111\n",
      "First hit for audio 3 at iteration 0\n",
      "It's way over 0.0006224086880683899\n",
      "Worked i=4 loss=0.000034 bound=1.120336\n",
      "First hit for audio 4 at iteration 0\n",
      "It's way over 2.0093873143196107e-05\n",
      "Worked i=9 loss=0.000032 bound=0.036169\n",
      "First hit for audio 9 at iteration 0\n",
      "It's way over 0.00795130491256714\n",
      "Worked i=10 loss=0.000265 bound=14.312349\n",
      "First hit for audio 10 at iteration 0\n",
      "It's way over 0.001740925431251526\n",
      "Worked i=11 loss=0.000033 bound=3.133666\n",
      "First hit for audio 11 at iteration 0\n",
      "It's way over 0.007176779270172119\n",
      "Worked i=12 loss=0.000095 bound=12.918202\n",
      "First hit for audio 12 at iteration 0\n",
      "It's way over 0.0007686190009117127\n",
      "Worked i=13 loss=0.000036 bound=1.383514\n",
      "First hit for audio 13 at iteration 0\n",
      "It's way over 0.006598480224609375\n",
      "Worked i=14 loss=0.000085 bound=11.877264\n",
      "First hit for audio 14 at iteration 0\n",
      "It's way over 0.0007880818843841553\n",
      "Worked i=17 loss=0.000033 bound=1.418548\n",
      "First hit for audio 17 at iteration 0\n",
      "It's way over 0.0002967561185359955\n",
      "Worked i=20 loss=0.000033 bound=0.534161\n",
      "First hit for audio 20 at iteration 0\n",
      "It's way over 2.0283961668610574e-05\n",
      "Worked i=21 loss=0.000029 bound=0.036511\n",
      "First hit for audio 21 at iteration 0\n",
      "It's way over 0.0058542642593383785\n",
      "Worked i=22 loss=0.000050 bound=10.537676\n",
      "First hit for audio 22 at iteration 0\n",
      "It's way over 0.000338914692401886\n",
      "Worked i=23 loss=0.000024 bound=0.610046\n",
      "First hit for audio 23 at iteration 0\n",
      "It's way over 0.000247290700674057\n",
      "Worked i=26 loss=0.000031 bound=0.445123\n",
      "First hit for audio 26 at iteration 0\n",
      "It's way over 0.00017893603444099426\n",
      "Worked i=29 loss=0.000037 bound=0.322085\n",
      "First hit for audio 29 at iteration 0\n",
      "It's way over 0.005957175254821778\n",
      "Worked i=30 loss=0.000120 bound=10.722915\n",
      "First hit for audio 30 at iteration 0\n",
      "It's way over 0.000182124525308609\n",
      "Worked i=31 loss=0.000032 bound=0.327824\n",
      "First hit for audio 31 at iteration 0\n",
      "It's way over 0.0014159125089645386\n",
      "Worked i=32 loss=0.000043 bound=2.548642\n",
      "First hit for audio 32 at iteration 0\n",
      "It's way over 0.0011832098960876465\n",
      "Worked i=34 loss=0.000036 bound=2.129778\n",
      "First hit for audio 34 at iteration 0\n",
      "It's way over 0.0016008875370025636\n",
      "Worked i=35 loss=0.000070 bound=2.881598\n",
      "First hit for audio 35 at iteration 0\n",
      "It's way over 0.000272737443447113\n",
      "Worked i=36 loss=0.000031 bound=0.490927\n",
      "First hit for audio 36 at iteration 0\n",
      "It's way over 0.0008817695379257203\n",
      "Worked i=37 loss=0.000045 bound=1.587185\n",
      "First hit for audio 37 at iteration 0\n",
      "It's way over 5.93529175966978e-06\n",
      "Worked i=38 loss=0.000031 bound=0.010684\n",
      "First hit for audio 38 at iteration 0\n",
      "It's way over 0.0005395334959030152\n",
      "Worked i=39 loss=0.000031 bound=0.971160\n",
      "First hit for audio 39 at iteration 0\n",
      "It's way over 3.52204330265522e-05\n",
      "Worked i=42 loss=0.000030 bound=0.063397\n",
      "First hit for audio 42 at iteration 0\n",
      "It's way over 0.0001291264295578003\n",
      "Worked i=43 loss=0.000028 bound=0.232428\n",
      "First hit for audio 43 at iteration 0\n",
      "It's way over 0.00034072819352149966\n",
      "Worked i=44 loss=0.000067 bound=0.613311\n",
      "First hit for audio 44 at iteration 0\n",
      "It's way over 0.00010559196025133133\n",
      "Worked i=46 loss=0.000026 bound=0.190066\n",
      "First hit for audio 46 at iteration 0\n",
      "It's way over 0.00044053369760513306\n",
      "Worked i=48 loss=0.000028 bound=0.792961\n",
      "First hit for audio 48 at iteration 0\n",
      "It's way over 0.0018170489072799683\n",
      "Worked i=54 loss=0.000052 bound=3.270688\n",
      "First hit for audio 54 at iteration 0\n",
      "It's way over 4.222159087657929e-05\n",
      "Worked i=55 loss=0.000033 bound=0.075999\n",
      "First hit for audio 55 at iteration 0\n",
      "It's way over 0.00291884970664978\n",
      "Worked i=56 loss=0.000027 bound=5.253930\n",
      "First hit for audio 56 at iteration 0\n",
      "It's way over 0.0015791836977005005\n",
      "Worked i=57 loss=0.000056 bound=2.842531\n",
      "First hit for audio 57 at iteration 0\n",
      "It's way over 0.0023181121349334717\n",
      "Worked i=59 loss=0.000033 bound=4.172602\n",
      "First hit for audio 59 at iteration 0\n",
      "It's way over 0.0024614176750183104\n",
      "Worked i=61 loss=0.000042 bound=4.430552\n",
      "First hit for audio 61 at iteration 0\n",
      "It's way over 7.269088923931122e-05\n",
      "Worked i=63 loss=0.000028 bound=0.130844\n",
      "First hit for audio 63 at iteration 0\n",
      "It's way over 0.00037861135601997375\n",
      "Worked i=64 loss=0.000041 bound=0.681500\n",
      "First hit for audio 64 at iteration 0\n",
      "It's way over 0.0020446529388427736\n",
      "Worked i=66 loss=0.000046 bound=3.680375\n",
      "First hit for audio 66 at iteration 0\n",
      "It's way over 0.007302738189697265\n",
      "Worked i=68 loss=0.000144 bound=13.144929\n",
      "First hit for audio 68 at iteration 0\n",
      "It's way over 8.92169214785099e-06\n",
      "Worked i=69 loss=0.000028 bound=0.016059\n",
      "First hit for audio 69 at iteration 0\n",
      "It's way over 0.00019425392150878906\n",
      "Worked i=70 loss=0.000037 bound=0.349657\n",
      "First hit for audio 70 at iteration 0\n",
      "It's way over 0.003968506813049316\n",
      "Worked i=71 loss=0.000064 bound=7.143312\n",
      "First hit for audio 71 at iteration 0\n",
      "It's way over 0.008060931205749512\n",
      "Worked i=72 loss=0.065604 bound=14.509676\n",
      "First hit for audio 72 at iteration 0\n",
      "It's way over 0.007683564186096192\n",
      "Worked i=75 loss=0.006178 bound=13.830415\n",
      "First hit for audio 75 at iteration 0\n",
      "It's way over 0.003482004404067993\n",
      "Worked i=76 loss=0.000058 bound=6.267608\n",
      "First hit for audio 76 at iteration 0\n",
      "It's way over 0.006323297500610351\n",
      "Worked i=77 loss=0.000125 bound=11.381935\n",
      "First hit for audio 77 at iteration 0\n",
      "It's way over 0.0016175457239151001\n",
      "Worked i=80 loss=0.000039 bound=2.911582\n",
      "First hit for audio 80 at iteration 0\n",
      "It's way over 0.00045384526252746583\n",
      "Worked i=82 loss=0.000027 bound=0.816921\n",
      "First hit for audio 82 at iteration 0\n",
      "It's way over 4.053325578570366e-05\n",
      "Worked i=83 loss=0.000033 bound=0.072960\n",
      "First hit for audio 83 at iteration 0\n",
      "It's way over 7.289142906665802e-05\n",
      "Worked i=84 loss=0.000035 bound=0.131205\n",
      "First hit for audio 84 at iteration 0\n",
      "It's way over 0.00015083034336566925\n",
      "Worked i=85 loss=0.000035 bound=0.271495\n",
      "First hit for audio 85 at iteration 0\n",
      "It's way over 0.00020730586349964141\n",
      "Worked i=86 loss=0.000032 bound=0.373151\n",
      "First hit for audio 86 at iteration 0\n",
      "It's way over 0.00011511614173650742\n",
      "Worked i=87 loss=0.000028 bound=0.207209\n",
      "First hit for audio 87 at iteration 0\n",
      "It's way over 0.0007574153542518616\n",
      "Worked i=88 loss=0.000038 bound=1.363348\n",
      "First hit for audio 88 at iteration 0\n",
      "It's way over 1.6053294762969018e-05\n",
      "Worked i=91 loss=0.000036 bound=0.028896\n",
      "First hit for audio 91 at iteration 0\n",
      "It's way over 0.007565439224243164\n",
      "Worked i=93 loss=0.000113 bound=13.617790\n",
      "First hit for audio 93 at iteration 0\n",
      "It's way over 0.00561494779586792\n",
      "Worked i=95 loss=0.000056 bound=10.106906\n",
      "First hit for audio 95 at iteration 0\n",
      "It's way over 0.0026698760986328127\n",
      "Worked i=98 loss=0.000040 bound=4.805777\n",
      "First hit for audio 98 at iteration 0\n",
      "It's way over 0.0005593958497047424\n",
      "Worked i=102 loss=0.000032 bound=1.006913\n",
      "First hit for audio 102 at iteration 0\n",
      "It's way over 6.428580731153488e-05\n",
      "Worked i=103 loss=0.000030 bound=0.115714\n",
      "First hit for audio 103 at iteration 0\n",
      "It's way over 0.0015365304946899415\n",
      "Worked i=104 loss=0.000069 bound=2.765755\n",
      "First hit for audio 104 at iteration 0\n",
      "It's way over 0.001413838267326355\n",
      "Worked i=107 loss=0.000029 bound=2.544909\n",
      "First hit for audio 107 at iteration 0\n",
      "It's way over 0.00651140832901001\n",
      "Worked i=108 loss=0.000060 bound=11.720535\n",
      "First hit for audio 108 at iteration 0\n",
      "It's way over 0.0009492821097373962\n",
      "Worked i=109 loss=0.000043 bound=1.708708\n",
      "First hit for audio 109 at iteration 0\n",
      "It's way over 0.00011259409040212631\n",
      "Worked i=110 loss=0.000033 bound=0.202669\n",
      "First hit for audio 110 at iteration 0\n",
      "It's way over 1.1267726309597493e-05\n",
      "Worked i=113 loss=0.000029 bound=0.020282\n",
      "First hit for audio 113 at iteration 0\n",
      "It's way over 0.003433732271194458\n",
      "Worked i=115 loss=0.000061 bound=6.180718\n",
      "First hit for audio 115 at iteration 0\n",
      "It's way over 0.0031005730628967283\n",
      "Worked i=116 loss=0.000071 bound=5.581031\n",
      "First hit for audio 116 at iteration 0\n",
      "It's way over 0.00592619514465332\n",
      "Worked i=119 loss=0.000043 bound=10.667150\n",
      "First hit for audio 119 at iteration 0\n",
      "It's way over 8.422346413135528e-05\n",
      "Worked i=120 loss=0.000032 bound=0.151602\n",
      "First hit for audio 120 at iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's way over 0.0013459372520446778\n",
      "Worked i=121 loss=0.000068 bound=2.422687\n",
      "First hit for audio 121 at iteration 0\n",
      "It's way over 3.0213011428713797e-05\n",
      "Worked i=122 loss=0.000027 bound=0.054383\n",
      "First hit for audio 122 at iteration 0\n",
      "It's way over 0.0024870681762695314\n",
      "Worked i=124 loss=0.000050 bound=4.476722\n",
      "First hit for audio 124 at iteration 0\n",
      "It's way over 2.4236559867858888e-05\n",
      "Worked i=126 loss=0.000030 bound=0.043626\n",
      "First hit for audio 126 at iteration 0\n",
      "It's way over 0.0003813751041889191\n",
      "Worked i=127 loss=0.000030 bound=0.686475\n",
      "First hit for audio 127 at iteration 0\n",
      "It's way over 0.08200850677490235\n",
      "Worked i=0 loss=0.000028 bound=147.615311\n",
      "First hit for audio 0 at iteration 99\n",
      "It's way over 0.08200885772705079\n",
      "Worked i=2 loss=0.000027 bound=147.615952\n",
      "First hit for audio 2 at iteration 99\n",
      "It's way over 0.08200356292724609\n",
      "Worked i=5 loss=0.000030 bound=147.606415\n",
      "First hit for audio 5 at iteration 99\n",
      "It's way over 0.11853781127929687\n",
      "Worked i=6 loss=0.000028 bound=213.368057\n",
      "First hit for audio 6 at iteration 99\n",
      "It's way over 0.08200882720947265\n",
      "Worked i=7 loss=0.000031 bound=147.615875\n",
      "First hit for audio 7 at iteration 99\n",
      "It's way over 0.081999755859375\n",
      "Worked i=8 loss=0.000028 bound=147.599564\n",
      "First hit for audio 8 at iteration 99\n",
      "It's way over 0.08198464965820312\n",
      "Worked i=15 loss=0.000041 bound=147.572372\n",
      "First hit for audio 15 at iteration 99\n",
      "It's way over 0.08200978851318359\n",
      "Worked i=16 loss=0.000031 bound=147.617615\n",
      "First hit for audio 16 at iteration 99\n",
      "It's way over 0.1185284423828125\n",
      "Worked i=18 loss=0.000026 bound=213.351196\n",
      "First hit for audio 18 at iteration 99\n",
      "It's way over 0.14698634338378908\n",
      "Worked i=19 loss=0.000031 bound=264.575409\n",
      "First hit for audio 19 at iteration 99\n",
      "It's way over 0.08200738525390625\n",
      "Worked i=24 loss=0.000026 bound=147.613281\n",
      "First hit for audio 24 at iteration 99\n",
      "It's way over 0.08198941040039062\n",
      "Worked i=25 loss=0.000031 bound=147.580933\n",
      "First hit for audio 25 at iteration 99\n",
      "It's way over 0.08199148559570313\n",
      "Worked i=27 loss=0.000027 bound=147.584671\n",
      "First hit for audio 27 at iteration 99\n",
      "It's way over 0.08200691223144531\n",
      "Worked i=28 loss=0.000031 bound=147.612442\n",
      "First hit for audio 28 at iteration 99\n",
      "It's way over 0.14679039001464844\n",
      "Worked i=33 loss=0.000032 bound=264.222687\n",
      "First hit for audio 33 at iteration 99\n",
      "It's way over 0.08196564483642578\n",
      "Worked i=40 loss=0.000033 bound=147.538177\n",
      "First hit for audio 40 at iteration 99\n",
      "It's way over 0.12381571960449218\n",
      "Worked i=41 loss=0.000030 bound=222.868286\n",
      "First hit for audio 41 at iteration 99\n",
      "It's way over 0.08200877380371094\n",
      "Worked i=45 loss=0.000031 bound=147.615784\n",
      "First hit for audio 45 at iteration 99\n",
      "It's way over 0.08186050415039063\n",
      "Worked i=47 loss=0.000036 bound=147.348907\n",
      "First hit for audio 47 at iteration 99\n",
      "It's way over 0.08318256378173829\n",
      "Worked i=49 loss=0.000030 bound=149.728622\n",
      "First hit for audio 49 at iteration 99\n",
      "It's way over 0.1214229736328125\n",
      "Worked i=50 loss=0.000035 bound=218.561356\n",
      "First hit for audio 50 at iteration 99\n",
      "It's way over 0.14766123962402344\n",
      "Worked i=51 loss=0.000128 bound=265.790222\n",
      "First hit for audio 51 at iteration 99\n",
      "It's way over 0.14259690856933593\n",
      "Worked i=52 loss=0.000035 bound=256.674438\n",
      "First hit for audio 52 at iteration 99\n",
      "It's way over 0.08200515747070312\n",
      "Worked i=53 loss=0.000037 bound=147.609283\n",
      "First hit for audio 53 at iteration 99\n",
      "It's way over 0.11835387420654297\n",
      "Worked i=58 loss=0.000037 bound=213.036972\n",
      "First hit for audio 58 at iteration 99\n",
      "It's way over 0.12380322265625\n",
      "Worked i=60 loss=0.000028 bound=222.845795\n",
      "First hit for audio 60 at iteration 99\n",
      "It's way over 0.0820031509399414\n",
      "Worked i=62 loss=0.000028 bound=147.605667\n",
      "First hit for audio 62 at iteration 99\n",
      "It's way over 0.11851045227050781\n",
      "Worked i=65 loss=0.000027 bound=213.318817\n",
      "First hit for audio 65 at iteration 99\n",
      "It's way over 0.1337397003173828\n",
      "Worked i=67 loss=0.000084 bound=240.731445\n",
      "First hit for audio 67 at iteration 99\n",
      "It's way over 0.08178001403808594\n",
      "Worked i=73 loss=0.000034 bound=147.204025\n",
      "First hit for audio 73 at iteration 99\n",
      "It's way over 0.1434646911621094\n",
      "Worked i=74 loss=0.000053 bound=258.236450\n",
      "First hit for audio 74 at iteration 99\n",
      "It's way over 0.14785089111328126\n",
      "Worked i=78 loss=0.000030 bound=266.131592\n",
      "First hit for audio 78 at iteration 99\n",
      "It's way over 0.0820096435546875\n",
      "Worked i=79 loss=0.000035 bound=147.617355\n",
      "First hit for audio 79 at iteration 99\n",
      "It's way over 0.08200530242919922\n",
      "Worked i=81 loss=0.000027 bound=147.609528\n",
      "First hit for audio 81 at iteration 99\n",
      "It's way over 0.08200808715820312\n",
      "Worked i=89 loss=0.000029 bound=147.614548\n",
      "First hit for audio 89 at iteration 99\n",
      "It's way over 0.08197150421142578\n",
      "Worked i=90 loss=0.000032 bound=147.548706\n",
      "First hit for audio 90 at iteration 99\n",
      "It's way over 0.08200334930419922\n",
      "Worked i=92 loss=0.000034 bound=147.606033\n",
      "First hit for audio 92 at iteration 99\n",
      "It's way over 0.11902166748046875\n",
      "Worked i=94 loss=0.000074 bound=214.238998\n",
      "First hit for audio 94 at iteration 99\n",
      "It's way over 0.11852085876464843\n",
      "Worked i=96 loss=0.000028 bound=213.337540\n",
      "First hit for audio 96 at iteration 99\n",
      "It's way over 0.08155686950683594\n",
      "Worked i=97 loss=0.000038 bound=146.802368\n",
      "First hit for audio 97 at iteration 99\n",
      "It's way over 0.08200443267822266\n",
      "Worked i=99 loss=0.000037 bound=147.607986\n",
      "First hit for audio 99 at iteration 99\n",
      "It's way over 0.12119443511962891\n",
      "Worked i=100 loss=0.000039 bound=218.149994\n",
      "First hit for audio 100 at iteration 99\n",
      "It's way over 0.08187226867675781\n",
      "Worked i=101 loss=0.000040 bound=147.370087\n",
      "First hit for audio 101 at iteration 99\n",
      "It's way over 0.08200083160400391\n",
      "Worked i=105 loss=0.000032 bound=147.601486\n",
      "First hit for audio 105 at iteration 99\n",
      "It's way over 0.08166437530517578\n",
      "Worked i=106 loss=0.000044 bound=146.995865\n",
      "First hit for audio 106 at iteration 99\n",
      "It's way over 0.08200689697265626\n",
      "Worked i=111 loss=0.000036 bound=147.612411\n",
      "First hit for audio 111 at iteration 99\n",
      "It's way over 0.14754946899414062\n",
      "Worked i=112 loss=0.000029 bound=265.589020\n",
      "First hit for audio 112 at iteration 99\n",
      "It's way over 0.1449724884033203\n",
      "Worked i=114 loss=0.000041 bound=260.950470\n",
      "First hit for audio 114 at iteration 99\n",
      "It's way over 0.08200114440917969\n",
      "Worked i=117 loss=0.000035 bound=147.602051\n",
      "First hit for audio 117 at iteration 99\n",
      "It's way over 0.08199252319335938\n",
      "Worked i=118 loss=0.000031 bound=147.586533\n",
      "First hit for audio 118 at iteration 99\n",
      "It's way over 0.08200928497314453\n",
      "Worked i=123 loss=0.000033 bound=147.616714\n",
      "First hit for audio 123 at iteration 99\n",
      "It's way over 0.11855762481689452\n",
      "Worked i=125 loss=0.000025 bound=213.403732\n",
      "First hit for audio 125 at iteration 99\n",
      "adv_tmp/test \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of total examples: 256\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttack started for testing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m start3\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 102\u001b[0m adv_test_ds\u001b[38;5;241m=\u001b[39m\u001b[43mcw_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m end3\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttack finished for testing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mcw_attack\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adv_train_ds\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     adv_test_ds\u001b[38;5;241m=\u001b[39m\u001b[43mcollect_test_adversarial_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madv_tmp/\u001b[39;49m\u001b[38;5;132;43;01m{k}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madversarial test data uploaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adv_test_ds\n",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m, in \u001b[0;36mcollect_test_adversarial_data\u001b[0;34m(batch_size, data_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((data_dir, input_data))\n\u001b[1;32m      9\u001b[0m     adv_test_files\u001b[38;5;241m.\u001b[39mappend(input_data)\n\u001b[0;32m---> 10\u001b[0m adv_test_data,adv_test_label\u001b[38;5;241m=\u001b[39m\u001b[43mload_test_adversarial_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_test_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcommands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     11\u001b[0m adv_test_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((adv_test_data, adv_test_label))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adv_test_ds\n",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m, in \u001b[0;36mload_test_adversarial_data\u001b[0;34m(adv_test_files, commands, data_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m adv_test_data\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m adv_test_label\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mtest_files\u001b[49m):\n\u001b[1;32m      6\u001b[0m     data, label \u001b[38;5;241m=\u001b[39m  create_example(fp, commands, data_dir,trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     test_data\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_files' is not defined"
     ]
    }
   ],
   "source": [
    "start2=time.time()\n",
    "data_dir =args.data_dir\n",
    "train_ds, test_ds, val_ds, commands = collect_data(batch_size=args.batch_size, data_dir=data_dir)\n",
    "print(\"train_ds, test_ds, val_ds uploaded\")\n",
    "model = KWS_transformer(\n",
    "    image_size=(40, 98),\n",
    "    patch_size=(20, 2),\n",
    "    num_layers=args.num_layers,\n",
    "    num_classes=len(commands),\n",
    "    d_model=args.d_model,\n",
    "    num_heads=args.num_heads,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    dropout=0\n",
    ")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ),\n",
    "    optimizer=tfa.optimizers.AdamW(\n",
    "        learning_rate=args.lr, weight_decay=args.weight_decay\n",
    "    ),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "np.random.seed(1234)\n",
    "perm = np.random.permutation(40)\n",
    "best_val_acc = 0\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "train=[]\n",
    "val=[]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for i in range(args.epochs):\n",
    "        loss, acc, batches = 0, 0, 0\n",
    "        for data, labels in train_ds:\n",
    "            #generate adversarial samples using carlini and wagner attack here add it too the training phase\n",
    "            # creation of combined adversarial and benign samples using concatentation\n",
    "            #adv_data,labels=c&w(data,labels)\n",
    "            #adv_mfccs=convert_to_mfccs(adv_data,perm=perm)\n",
    "            #l,a=model.train_on_batch(adv_mfccs,labels)\n",
    "            mfccs = convert_to_mfccs(data, perm = perm)\n",
    "            l, a = model.train_on_batch(mfccs, labels)\n",
    "            loss += l\n",
    "            acc +=a\n",
    "            \n",
    "            batches += 1    \n",
    "        train.append((acc/batches)*100)\n",
    "        train_loss.append((loss/batches))    \n",
    "        print(f\"Epoch: {i}, Train: Loss: {(loss/batches)}, acc: {(acc/batches)*100}\")\n",
    "        loss, acc, batches=0,0,0\n",
    "        if(i==0):   \n",
    "            print(\"Attack started for training\")\n",
    "            start=time.time()\n",
    "            adv_train_ds=cw_attack(val=\"train\")\n",
    "            end=time.time()\n",
    "            \n",
    "            print(\"Attack finished for training\")\n",
    "            print(\"attack time\",end=\"\")\n",
    "            print(end-start)\n",
    "            print(\" Adversarial training completed for {iterate} iteration\".format(iterate=i+1))\n",
    "            print(\"\\n\\n\\n\\n\\n\")\n",
    "            for adv_data,labels in adv_train_ds:\n",
    "                mfccs=convert_to_mfccs(adv_data,perm=perm)\n",
    "                adv_l,adv_a=model.train_on_batch(mfccs,labels)\n",
    "                loss+=adv_l\n",
    "                acc+=adv_a\n",
    "                batches+=1\n",
    "            print(f\"Epoch: {i}, Adv Train: Loss: {(loss/batches)}, acc: {(acc/batches)*100}\")\n",
    "    \n",
    "        loss, acc, batches = 0, 0, 0\n",
    "        for data, labels in val_ds:\n",
    "            mfccs = convert_to_mfccs(data, perm = perm)\n",
    "            l, a = model.test_on_batch(mfccs, labels)\n",
    "            loss += l\n",
    "            acc += a\n",
    "            batches += 1\n",
    "        val.append((acc/batches)*100)\n",
    "        val_loss.append((loss/batches))   \n",
    "        print(f\"Epoch: {i}, Val: Loss: {(loss/batches)}, acc: {(acc/batches)*100}\")\n",
    "        if acc > best_val_acc:\n",
    "            best_val_acc = acc\n",
    "            model.save_weights(\"best_weights\")\n",
    "plt.plot(train)\n",
    "plt.plot(val)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Epoch vs  Accuracy')\n",
    "plt.show()         \n",
    "model.save(args.save_dir)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Epoch vs loss')\n",
    "plt.show()\n",
    "model.save(args.save_dir)\n",
    "test_ds = test_ds.batch(args.batch_size)\n",
    "loss, acc, batches = 0, 0, 0\n",
    "print(\"Attack started for testing\")\n",
    "start3=time.time()\n",
    "adv_test_ds=cw_attack(val=\"test\")\n",
    "end3=time.time()\n",
    "print(\"Attack finished for testing\")\n",
    "print(\"attack time\",end=\"\")\n",
    "print(end3-start3)\n",
    "adv_test_ds = adv_test_ds.batch(args.batch_size)\n",
    "#print(\" Adversarial training completed for {iterate} iteration\".format(iterate=i+1))\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "for data, labels in test_ds:\n",
    "    mfccs = convert_to_mfccs(data, perm = perm)\n",
    "    l, a = model.test_on_batch(mfccs, labels)\n",
    "    loss += l\n",
    "    acc += a\n",
    "    batches += 1\n",
    "for data,labels in adv_test_ds:\n",
    "    mfccs = convert_to_mfccs(data, perm = perm)\n",
    "    l, a = model.test_on_batch(mfccs, labels)\n",
    "    loss += l\n",
    "    acc += a\n",
    "    batches += 1\n",
    "    \n",
    "print(f\"Test: Loss: {(loss/batches)}, acc: {(acc/batches)*100}\")\n",
    "end2=time.time()\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "\n",
    "print(end2-start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv_train_dir=\n",
    "os.makedirs(\"tp/{val}\".format(val=0), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016e01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
