{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403d3af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:04.439544Z",
     "iopub.status.busy": "2023-02-12T14:56:04.438952Z",
     "iopub.status.idle": "2023-02-12T14:56:05.459189Z",
     "shell.execute_reply": "2023-02-12T14:56:05.457779Z"
    },
    "papermill": {
     "duration": 1.029851,
     "end_time": "2023-02-12T14:56:05.461762",
     "exception": false,
     "start_time": "2023-02-12T14:56:04.431911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tmp’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe08eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:05.471640Z",
     "iopub.status.busy": "2023-02-12T14:56:05.471290Z",
     "iopub.status.idle": "2023-02-12T14:56:13.035631Z",
     "shell.execute_reply": "2023-02-12T14:56:13.034413Z"
    },
    "papermill": {
     "duration": 7.572644,
     "end_time": "2023-02-12T14:56:13.038422",
     "exception": false,
     "start_time": "2023-02-12T14:56:05.465778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:38:43.031120: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:38:43.460582: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-27 16:38:43.499797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:38:43.499825: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:38:44.566053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:38:44.566121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:38:44.566128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:38:46.935391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:38:46.935639: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:38:46.935671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ritik-Inspiron-15-3511): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:38:46.939104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from shutil import copyfile\n",
    "import scipy.io.wavfile as wav\n",
    "import struct\n",
    "import time\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "import json\n",
    "import os\n",
    "import librosa\n",
    "   \n",
    "    \n",
    "def training_step(model, optimizer, loss_fn, original, delta, rescale, target):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([delta])\n",
    "#         print(delta.shape, rescale.shape)\n",
    "        new_delta = tf.clip_by_value(delta, -2000, 2000)*rescale\n",
    "        new_input = new_delta + original\n",
    "        noise = tf.random.normal(new_input.shape, stddev=2)\n",
    "        new_input = tf.clip_by_value(new_input+noise, -2**15, 2**15-1)\n",
    "#         print('input:', new_input.shape)\n",
    "        stfts = tf.signal.stft(new_input, frame_length=480, frame_step=160, fft_length=480)\n",
    "        spectrograms = tf.abs(stfts)\n",
    "#         print('stft:', stfts.shape)\n",
    "        # Warp the linear scale spectrograms into the mel-scale.\n",
    "        num_spectrogram_bins = stfts.shape[-1]\n",
    "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 7600.0, 80\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "          num_mel_bins, num_spectrogram_bins, 16000, lower_edge_hertz,\n",
    "          upper_edge_hertz)\n",
    "#         print(linear_to_mel_weight_matrix.shape)\n",
    "        mel_spectrograms = tf.tensordot(\n",
    "          spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "#         print(mel_spectrograms.shape)\n",
    "        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
    "          linear_to_mel_weight_matrix.shape[-1:]))\n",
    "#         print(mel_spectrograms.shape)\n",
    "        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "        # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n",
    "          log_mel_spectrograms)[..., :40]\n",
    "        mfccs = tf.transpose(mfccs, perm=[0,2,1])\n",
    "        mfccs = tf.expand_dims(mfccs, axis=-1)\n",
    "\n",
    "        pred = model(mfccs)\n",
    "\n",
    "        loss = loss_fn(target, pred)\n",
    "    dd = tape.gradient(loss, [delta])\n",
    "#             print('\\n\\n\\nhere\\n\\n\\n', grad, var)\n",
    "    optimizer.apply_gradients(zip(dd,[delta]))\n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "def attack(audio, files, target, model, root = 'tmp', optimizer = tf.optimizers.Adam(learning_rate=10), \n",
    "           loss_fn=tf.nn.sparse_softmax_cross_entropy_with_logits):\n",
    "    batch_size = len(audio)\n",
    "    delta = tf.Variable(np.zeros((batch_size, 16000), dtype=np.float32))\n",
    "    rescale = tf.Variable(np.ones((batch_size, 1), dtype = np.float32))\n",
    "    original = tf.convert_to_tensor(np.array(audio, dtype=np.float32))\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    new_input = (original + delta).numpy()\n",
    "    \n",
    "    # Here we'll keep track of the best solution we've found so far\n",
    "    final_deltas = [None]*batch_size\n",
    "\n",
    "\n",
    "\n",
    "    # We'll make a bunch of iterations of gradient descent here\n",
    "    #now = time.time()\n",
    "    MAX = 10000\n",
    "    first_hits = np.zeros((batch_size,))\n",
    "    best_hits = np.zeros((batch_size,))\n",
    "    start = time.time()\n",
    "    for i in range(MAX):\n",
    "\n",
    "        pred, loss = training_step(model, optimizer, loss_fn, original, delta, rescale, target)\n",
    "\n",
    "\n",
    "        # Print out some debug information every 10 iterations.\n",
    "        if i%100 == 0:\n",
    "#             print(pred.shape, pred)\n",
    "            print(time.time() - start)\n",
    "            print(i, loss, np.argmax(pred, axis=1))\n",
    "\n",
    "\n",
    "        # Actually do the optimization step\n",
    "        for ii in range(batch_size):\n",
    "            if (i%100 == 0 and np.argmax(pred[ii]) == target[ii]) \\\n",
    "               or (i == MAX-1 and final_deltas[ii] is None):\n",
    "                temp_rescale = rescale.numpy()\n",
    "                # Get the current constant\n",
    "                if temp_rescale[ii][0]*2000 > np.max(np.abs(delta[ii])):\n",
    "                    print(\"It's way over\", np.max(np.abs(delta[ii]))/2000.0)\n",
    "                    temp_rescale[ii][0] = np.max(np.abs(delta[ii]))/2000.0\n",
    "\n",
    "                temp_rescale[ii][0] *= .9\n",
    "                rescale.assign(temp_rescale)\n",
    "                # Adjust the best solution found so far\n",
    "                new_input[ii] = (original[ii] + delta[ii]).numpy()\n",
    "                final_deltas[ii] = new_input[ii]\n",
    "\n",
    "                print(\"Worked i=%d loss=%f bound=%f\"%(ii, loss[ii], 2000*rescale[ii][0]))\n",
    "\n",
    "                if (first_hits[ii] == 0):\n",
    "                    print(\"First hit for audio {} at iteration {}\".format(ii, i))\n",
    "                    first_hits[ii]=i\n",
    "                else:\n",
    "                    best_hits[ii]=i\n",
    "\n",
    "                # Just for debugging, save the adversarial example\n",
    "                # to /tmp so we can see it if we want\n",
    "                wav.write(f'{root}/{files[ii]}', 16000,\n",
    "                          np.array(np.clip(np.round(new_input[ii]),\n",
    "                                           -2**15, 2**15-1),dtype=np.int16))\n",
    "\n",
    "    return final_deltas, first_hits, best_hits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3f0cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:13.048703Z",
     "iopub.status.busy": "2023-02-12T14:56:13.047172Z",
     "iopub.status.idle": "2023-02-12T14:56:32.798243Z",
     "shell.execute_reply": "2023-02-12T14:56:32.797249Z"
    },
    "papermill": {
     "duration": 19.758165,
     "end_time": "2023-02-12T14:56:32.800496",
     "exception": false,
     "start_time": "2023-02-12T14:56:13.042331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /ML_KWS_TF2/work/CNN/CNN1/training/best/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# files = [\"down/31f01a8d_nohash_4.wav\", 'down/0b77ee66_nohash_1.wav', \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#          'left/0ff728b5_nohash_2.wav', 'left/f9273a21_nohash_0.wav',\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#          'right/d278d8ef_nohash_1.wav', 'right/1e02ffc5_nohash_1.wav',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# target = np.array([4]*len(audios))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# one_hot_target = tf.keras.utils.to_categorical(target, num_classes=10)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m/ML_KWS_TF2/work/CNN/CNN1/training/best/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39m#model = tf.keras.models.load_model('/kaggle/input/kwt-tf-mfcc/KWS_transformer')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m/ML_KWS_TF2/work/CNN/CNN1/training/best/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/saving/legacy/save.py:227\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    232\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    233\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    234\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at /ML_KWS_TF2/work/CNN/CNN1/training/best/"
     ]
    }
   ],
   "source": [
    "# files = [\"down/31f01a8d_nohash_4.wav\", 'down/0b77ee66_nohash_1.wav', \n",
    "#          'left/0ff728b5_nohash_2.wav', 'left/f9273a21_nohash_0.wav',\n",
    "#          'right/d278d8ef_nohash_1.wav', 'right/1e02ffc5_nohash_1.wav',\n",
    "#          'yes/df280250_nohash_0.wav', 'yes/7846fd85_nohash_4.wav',\n",
    "#          'no/baf01c1f_nohash_1.wav', 'no/e9bc5cc2_nohash_1.wav']\n",
    "\n",
    "# audios = []\n",
    "# for x in files:\n",
    "#     fs, audio = wav.read('/kaggle/input/speech-commands-v2/' + x)\n",
    "#     audios.append(audio)\n",
    "# target = np.array([4]*len(audios))\n",
    "# one_hot_target = tf.keras.utils.to_categorical(target, num_classes=10)\n",
    "#model=tf.keras.models.load_model('/ML_KWS_TF2/work/CNN/CNN1/training/best/')\n",
    "model = tf.keras.models.load_model('/kaggle/input/kwt-tf-mfcc/KWS_transformer')\n",
    "#model.load_weights('/ML_KWS_TF2/work/CNN/CNN1/training/best/')\n",
    "model.load_weights('/kaggle/input/kwt-tf-mfcc/best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1079ae29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:32.809531Z",
     "iopub.status.busy": "2023-02-12T14:56:32.809205Z",
     "iopub.status.idle": "2023-02-12T14:56:32.814158Z",
     "shell.execute_reply": "2023-02-12T14:56:32.813296Z"
    },
    "papermill": {
     "duration": 0.012024,
     "end_time": "2023-02-12T14:56:32.816479",
     "exception": false,
     "start_time": "2023-02-12T14:56:32.804455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deltas, firsts, bests = attack(audios, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6466cebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:32.825068Z",
     "iopub.status.busy": "2023-02-12T14:56:32.824786Z",
     "iopub.status.idle": "2023-02-12T14:56:32.829086Z",
     "shell.execute_reply": "2023-02-12T14:56:32.828039Z"
    },
    "papermill": {
     "duration": 0.011567,
     "end_time": "2023-02-12T14:56:32.831618",
     "exception": false,
     "start_time": "2023-02-12T14:56:32.820051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# diff = new-audio\n",
    "# source_DB = 20 * np.log10(np.max(np.abs(audio)))\n",
    "# end_DB = 20 * np.log10(np.max(np.abs(new)))\n",
    "# distortion = 20 * np.log10(np.max(np.abs(diff))) - source_DB\n",
    "# source_DB, end_DB, distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30b00e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:32.840030Z",
     "iopub.status.busy": "2023-02-12T14:56:32.839761Z",
     "iopub.status.idle": "2023-02-12T14:56:32.843969Z",
     "shell.execute_reply": "2023-02-12T14:56:32.842914Z"
    },
    "papermill": {
     "duration": 0.01132,
     "end_time": "2023-02-12T14:56:32.846587",
     "exception": false,
     "start_time": "2023-02-12T14:56:32.835267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# end_DB - source_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326ffb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:32.854947Z",
     "iopub.status.busy": "2023-02-12T14:56:32.854670Z",
     "iopub.status.idle": "2023-02-12T14:56:32.858875Z",
     "shell.execute_reply": "2023-02-12T14:56:32.857872Z"
    },
    "papermill": {
     "duration": 0.011291,
     "end_time": "2023-02-12T14:56:32.861441",
     "exception": false,
     "start_time": "2023-02-12T14:56:32.850150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 20*np.log10*(np.max(np.abs(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231db78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:56:32.869623Z",
     "iopub.status.busy": "2023-02-12T14:56:32.869329Z",
     "iopub.status.idle": "2023-02-12T14:57:10.565235Z",
     "shell.execute_reply": "2023-02-12T14:57:10.564165Z"
    },
    "papermill": {
     "duration": 37.702908,
     "end_time": "2023-02-12T14:57:10.567848",
     "exception": false,
     "start_time": "2023-02-12T14:56:32.864940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "commands = ['on', 'off', 'yes', 'no', 'stop', 'go', 'left', 'right', 'up', 'down']\n",
    "data_dir = '/kaggle/input/speech-commands-v2/'\n",
    "filenames = []\n",
    "for i in range(len(commands)):\n",
    "    filenames.append(tf.io.gfile.glob(str(data_dir) + commands[i] + \"/*.wav\"))\n",
    "\n",
    "filenames = list(chain.from_iterable(filenames))\n",
    "random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ccc67",
   "metadata": {
    "papermill": {
     "duration": 0.003564,
     "end_time": "2023-02-12T14:57:10.575679",
     "exception": false,
     "start_time": "2023-02-12T14:57:10.572115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc7802f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T14:57:10.586173Z",
     "iopub.status.busy": "2023-02-12T14:57:10.584166Z",
     "iopub.status.idle": "2023-02-12T20:42:12.328443Z",
     "shell.execute_reply": "2023-02-12T20:42:12.327343Z"
    },
    "papermill": {
     "duration": 20701.752355,
     "end_time": "2023-02-12T20:42:12.331574",
     "exception": false,
     "start_time": "2023-02-12T14:57:10.579219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     os\u001b[39m.\u001b[39;49mmkdir(\u001b[39m'\u001b[39;49m\u001b[39mtmp/\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m commands[i])\n\u001b[1;32m      3\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39m90\u001b[39m\n\u001b[1;32m      4\u001b[0m     audios \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/yes'"
     ]
    }
   ],
   "source": [
    "for i in range(2, 10):\n",
    "    os.mkdir('tmp/' + commands[i])\n",
    "    batch_size = 90\n",
    "    audios = []\n",
    "    files = []\n",
    "    j = -1\n",
    "    while len(audios) < batch_size:\n",
    "        j += 1\n",
    "        fs, audio = wav.read(filenames[j])\n",
    "        if filenames[j].split('/')[-2] == commands[i]:\n",
    "            continue\n",
    "        if audio.shape[0] == 16000:\n",
    "            audios.append(audio)\n",
    "            files.append('_'.join(filenames[j].split('/')[-2:]))\n",
    "    target = np.array([i]*len(audios))\n",
    "    deltas, firsts, bests = attack(audios, files, target, \n",
    "                                   model, root=f'tmp/{commands[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab212a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T20:42:12.663699Z",
     "iopub.status.busy": "2023-02-12T20:42:12.663253Z",
     "iopub.status.idle": "2023-02-12T20:42:12.668116Z",
     "shell.execute_reply": "2023-02-12T20:42:12.667070Z"
    },
    "papermill": {
     "duration": 0.171816,
     "end_time": "2023-02-12T20:42:12.670385",
     "exception": false,
     "start_time": "2023-02-12T20:42:12.498569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10 18\n",
    "# 32 21\n",
    "# 96 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f200e620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T20:42:13.302829Z",
     "iopub.status.busy": "2023-02-12T20:42:13.302281Z",
     "iopub.status.idle": "2023-02-12T20:42:13.316487Z",
     "shell.execute_reply": "2023-02-12T20:42:13.315394Z"
    },
    "papermill": {
     "duration": 0.416367,
     "end_time": "2023-02-12T20:42:13.319273",
     "exception": false,
     "start_time": "2023-02-12T20:42:12.902906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(r'/kaggle/working')\n",
    "\n",
    "# !zip -r attack.zip tmp\n",
    "\n",
    "# from IPython.display import FileLink\n",
    "\n",
    "# FileLink(r'attack.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9491a1db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T20:42:13.831850Z",
     "iopub.status.busy": "2023-02-12T20:42:13.831382Z",
     "iopub.status.idle": "2023-02-12T20:42:13.835843Z",
     "shell.execute_reply": "2023-02-12T20:42:13.834886Z"
    },
    "papermill": {
     "duration": 0.256422,
     "end_time": "2023-02-12T20:42:13.840824",
     "exception": false,
     "start_time": "2023-02-12T20:42:13.584402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91ae21",
   "metadata": {
    "papermill": {
     "duration": 0.246589,
     "end_time": "2023-02-12T20:42:14.334865",
     "exception": false,
     "start_time": "2023-02-12T20:42:14.088276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20781.016979,
   "end_time": "2023-02-12T20:42:17.410627",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-12T14:55:56.393648",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
